# 计算机网络（自顶向下）



🔻	代表重点



## 1.应用层（报文）

### 简介

​	主要是负责主机端之间的应用进程之间的通信，通过计算机网络发送报文进行通信，其中通信的方式主要有两种：

>   ​	客户——服务器	
>
>   ​	P2P						

​	其中进程向计算机网络发送报文的时候会经过套接字，也叫做应用程序接口（API）通俗来说就是家门口，套接字的作用有以下：

>   ​	保护应用进程的安全运行
>
>   ​	将抵达的报文准确地分配到指定地进程

​	此时也就将想要传送的数据运输到了运输层，这个时候就需要选择运输层的协议了，传输的时候我们需要考虑四点：

>   ​	保证数据的完整性
>
>   ​	吞吐量
>
>   ​	时延
>
>   ​	安全性

这个我们在运输层将会讨论。



应用层协议主要是规定：

1.  报文的类型

2.  报文的语法

3.  字段的语义

4.  何时发送报文

5.  报文响应规则

    

那么应用层协议都有哪些呢？

-   HTTP
-   FTP
-   SMTP
-   DNS
-   等等



---

### HTTP





其中HTTP是指超文本传输协议，主要是用户端的浏览器与WEB服务器端之间的交互协议。而且是无状态协议，因为服务器端是不保存客户端的访问以及客户的数据或任何信息（其主要是为了工程师方便开发高性能的服务器）。



HTTP客户与服务器端是使用的TCP运输层连接的，其中方式有

>   ​	非持续连接		
>
>   ​	持续连接			



为了解决HTTP无状态的缺点，设置了COOKIE允许服务器端能够对用户进行跟踪。分为四种：

>   ​	会话COOKIE（Session Cookies）
>
>   ​	永久性COOKIE
>
>   ​	安全性COOKIE
>
>   ​	HttpOnly 标记	（为了防止cookie被窃取）



为了解决客户——服务器请求响应较慢的问题，设置了WEB缓存进行初始服务器的代理。

1.  它可以缓存客户请求的数据进行快速响应，优化用户的体验。
2.  代理客户向初始服务器请求报文，节省了带宽的使用，降低了费用。
3.  为WEB网络环境减少了大量的数据流量，改善了所有应用的性能。





------

### FTP

下面介绍FTP协议，他和HTTP一样是文件传输协议，但是他是两个主机端通过FTP服务器进行通信也就是需要两个客户端。

而且连接比较特殊，使用了了两个并行的TCP连接进行通信：

>   ​	控制连接（传输控制信息：用户标识，口令等）
>
>   ​	数据连接



FTP会在会话的过程中保存用户的状态，也就是服务器会直接保存俩用户端的信息，这也大大限制了可以同时维持的会话总数。



---



### SMTP



SMTP（简单邮件传输协议）协议，但是该协议是在两个邮件服务器端之间起作用的，并非直接与客户电脑端。

因为客户是通过：客户——客户代理——邮件服务器——邮件服务器——客户代理——客户，进行邮件的传输的。

SMTP在邮件服务器之间传送一般是不通过中间邮件服务器的，这也就要求对方邮件服务器是开启的才能传输。

与HTTP协议相比虽然都是通过TCP传输，而且一般是持续连接的，但是还是有以下主要区别：

>   ​	HTTP是拉协议，SMTP是推协议
>
>   ​	SMTP要求报文使用7bitASCII码格式
>
>   ​	HTTP是分对象封装的，SMTP是全部一起封装的



接收方的客户并不是一直在线的，所以邮件服务器也将缓存该邮件信息，假设客户在线后且自己的PC就是客户代理，那么将需要主动向所属ISP邮件服务器请求邮件信息，但是SMTP是推协议只能向客户推送数据信息，此时无法使用该协议，那么该怎么办呢？

有以下的几种协议可以使用：

>   ​	POP3(第三版邮局协议)
>
>   ​	IMAP（因特网邮件协议）
>
>   ​	HTTP （基于WEB浏览器的电子邮件）



IMAP协议更加复杂，能够实现的功能更加多，而且会维护会话中的用户信息，并且可以只取得用户自己想要的邮件信息（获取报文组件）。





---



### DNS



DNS（**D**omain **N**ame **S**ystem）域名系统，通过UDP运输层协议进行下层通信，他是负责各个主机分配各自的ID系统，主要是负责将主机名转换成IP地址的目录服务，它通常为其他的应用层协议提供服务，例如：HTTP,FTP,SMTP等，这也会给因特网带来负担，这也就联想到了WEB缓存服务器，是不是可以仿造一个DNS缓存服务器，减少网络的负担。

DNS除了负责将主机名转换成IP地址的目录服务还有以下功能：

>   ​	主机别名
>
>   ​	邮件服务器别名
>
>   ​	负载分配

集中式的DNS服务器分布显然有很多的缺点例如：维护昂贵，单点故障，通信容量小等

所以一般采用树型分布式的DNS服务器，根DNS——顶级DNS——权威DNS——本地DNS

那么请求主机又是如何通过DNS找到自己指定IP地址的主机的呢的呢？

一般是先抵达本地DNS——根DNS——顶级DNS——权威DNS （逐个迭代查询目标IP地址）

显然这样的查找很费时也消耗网络资源，为此出现了DNS缓存，它使得本地DNS可以缓存任意DNS服务器传送回来的任何信息，一般两天后丢弃该信息。



DNS可以说是最健壮的网络协议，他几乎难以被攻击，一般也只有对请求主机的DDos攻击，但也可以通过调整DNS服务器进行处理。



---



### P2P

P2P，目前最为流行文件共享协议的是BitTorrent，它允许发送方与各个接收方都能够传输文件信息，也就是各个接受方都可以分享已经接收到的文件部分，大大降低了发送方的带宽压力。

其中客户——服务器模型下，最小分发文件时间与客户数量是线性增长的，

但是P2P模式下，是log函数增长的，这大大加快了文件的传输速度。



P2P主要是使用了分布式数据库技术，也叫做分布式散列表（DHT），他为接收方的各个对等方提供了查询的列表，一般有两种：

>   ​	环形DHT
>
>   ​	环形带捷径的DHT









## 2.运输层（报文段）



### 简介

​	运输层是为不同主机上的应用进程提供逻辑通信服务的，然后考虑计算机网络中最为基础性的问题上来，

>   ​	如何在可能丢失或者损坏数据的媒体上进行可靠的通信	（TCP是如何逐渐成长起来的）
>
>   ​	如何控制运输层实体的传输速率以避免网络拥塞				（处理拥塞的方法和原理）



​	==为什么叫做逻辑通信呢？==	

因为不需要考虑传输报文的物理基础设施的细节，例如：网络层的路由器，数据链路层的交换机，物理层的网线等。



​	应用层是基于主机端上的==进程之间==的通信层，而运输层是基于==主机端==之间的通信层

​	以此类推可以想到网络层，数据链路层，物理层是基于什么之间的。



整个计算机网络传输数据信息的时候的大致过程：

>   各个通信层之间都会对需要传输的数据进行封装，例如
>
>   应用层对需要传送的数据增加必要的信息例如：用户标识，报文类型等，形成一个==报文==。
>
>   运输层再将应用层传递下来的报文进行自己的封装，假如使用TCP传输协议就再添加所需要的信息例如：源端口号，目的端口号，检验和等，将一个报文分成多个==报文段==
>
>   网络层再从上级运输层接受到报文段之后，报文段加上IP地址后再为其添加该层运输时需要的必要标识信息，例如：IPV4中有校验码，IPV6中就简化了只有中转数等。此时也就形成了==数据包==，通过虚电路或者数据报的形式进行传输。
>
>   数据链路层，获取到网络层的数据包之后，通过子网掩码判断自己和目标的网段，若是同一网段就使用ARP协议直接解析目标IP的MAC地址，然后加上该地址和帧校验码FCS后形成==数据帧==交给物理层，若不是同一网段就使用ARP协议解析网关的MAC地址，将数据包交给路由器。
>
>   物理层，接收到数据帧之后将其解析成==二进制的数据流==在集线器和网线或者光纤或是无线波之间传输，抵达目的IP的MAC地址之后再逐层向上递交数据信息。这个过程也是逐步脱皮的过程，也就是逐层校验信息的准确性和完整性的时候。



而且，各个通信层之间的相关设备是无法处理上层的封装信息的，

例如：位于网络层之上的网络设备都称为网关，它可以处理运输层，应用层的数据

但是位于网络层的设备例如：路由器，只能处理网络层，数据链路层，物理层的封装数据信息，无法处理应用层和运输层。



-   集线器的做法：集线器是物理层的设备，只负责转发比特流
-   交换机的做法：将数据进行存储转发，他可以把比特流存储起来拆封装成数据帧，看到里面数据帧的MAC地址，根据目的MAC地址和自己的MAC地址表进行转发
-   路由器的做法：可以将传来的比特流存储起来拆封装成数据包，看到里面的IP地址，根据目的IP地址和自己的路由表将数据包交给下个路由器
-   最后到达PC3,主机将比特流接收后开始按照与发送端相反的步骤一层一层拆封装，直到把要接收的数据拆出来，一次通信完成。





运输层为应用层的进程提供服务，网络层为运输层的主机端提供服务。



打个比方：一个家庭有四个人，那么这个家庭就是主机端，人就是应用进程，那么他们需要和远方亲戚进行交流这个过程就可以类似于网络通信，那么为人之间提供服务的（比如说信件收集者）就是运输层提供的，为家庭之间提供服务的（比如说邮局）就是网络层，



那么运输层在应用层和网络层之间的交互方式有哪些呢？

>   ​	多路分解（将运输层报文段的数据交付到正确的套接字）
>
>   ​	多路复用（将运输层报文段的数据交付到网络层）



而在这里，TCP和UDP会有不同的处理方式，UDP会将不同的源IP地址和源端口号的报文段，但具有相同的目的IP地址和目的端口号定向到相同的套接字，而TCP会给两个不同的套接字给这两个报文段。

为什么呢？

因为TCP报文段是四元组的，它的报文段内包含了，源IP地址和源端口号，目的IP地址和目的端口号，而UDP仅仅包含了源端口号和目的端口号。



如今的高性能WEB服务器一般都只是使用一个应用进程，然后再为每一个新的用户连接船舰一个新的套接字的新线程（轻量级的子进程）

这里涉及到了HTTP协议中的非持续连接和持续连接的问题

例如：非持续的连接将会频繁地在服务器中建立新的套接字这将导致服务器性能降低，使用持续连接就是一直使用同一个套接字直到会话结束。



---



### UDP

​	User Datagram Protocol，用户数据报协议，他是无连接的协议，仅仅是对网络层增加了一点多路复用和多路分解的协议罢了。

​	实际上如果开发一个应用程序时选择了用UDP协议在运输层传输的话基本上就是相当于直接与网络层的IP协议打交道了，因为只是加了一个UDP首部罢了。



并且UDP协议的好处有如下几点：

>   ​	无需建立主机端之间的连接
>
>   ​	主机端不需要维护连接状态表，节省了计算机资源
>
>   ​	首部开销只有八个字节，TCP却有20个字节
>
>   ​	拥有简单的差错检验，报文段中的所有比特字节的和进行反码运算若全为二进制1，则正确，但是无法恢复差错，只是警告。



有以下缺点：

>   ​	没有拥塞控制，无法使发送源降低发送速率，且有可能引起高丢包率。
>
>   ​	不保证数据完整的传达到，所以需要发送源重新发送缺失数据



那么在UDP无法处理差错的情况下我们要怎么做呢？



---



### 数据传输协议



自然的想法就是直接重新传输一个新的差错的数据包过来，这个协议已经存在了，就叫自动重传请求（Automatic Repeat reQuest, ARQ）协议，

==ARQ协议==还需要考虑吧如下三种处理存在比特差错的情况。

>   ​	差错检测（不仅仅是检验所有比特字节和）
>
>   ​	接收方反馈
>
>   ​	重传



这也就形成了rdt2.0协议，但是，这个协议有个非常致命的弱点就是没有考虑到ACK/NAK分组受损/丢失的可能性。

解决这个问题有一个非常简单的方法就是将即将发送的==分组序号==放在该字段中，这个方法已经普遍置于多种协议之中。

这也就形成了改进的rdt2.1协议，但是这会使得重复发送很多ACK/NAK分组也就形成了大量的冗余分组。

那么聪明的同学应该也已经想到了应该如何解决这个问题，是的，就是设置一个==倒数定时器==，在这个时间段内如果还没接收到ACK/NAK，才会重新发送。

这就是rdt3.0协议：

>   ​	每次发送一个分组时，启动一个定时器
>
>   ​	响应定时器中断
>
>   ​	终止定时器



总结一下，需要稳定可靠完整的传输数据的数据传输协议需要的要点有哪些：

>   ​	检验和
>
>   ​	序号
>
>   ​	定时器
>
>   ​	ACK/NAK分组





好的，接下来我们考虑一下，传输协议之中是不是有ACK/NAK，也就是接收方确认收到后传回给发送方的信号，如果仅仅只是发送一个数据包再等待接收方返回ACK的话，信道以及发送方的利用率都很低，有什么办法可以改善这种情况呢？



是的，就是流水线的传输，想象一下，如果可以进行批量的发送数据报，而后再等待接收方返回一批量的ACK/NAK，是不是极大的提高了传输的效率。



但是再使用流水线技术下需要考虑如下的情况：

>   ​	增加序号的范围
>
>   ​	协议的发送方和接收方两端都需要一定的缓存空间
>
>   ​	以上两点的要求均取决于选择重传的协议是什么



流水线技术的重传协议有两个：==回退N步==，==选择重传==



### 回退N步



回退N步（GBN）协议又叫滑动窗口协议，他是由基序号（base），下一个序号（nextseqnum）也叫最小未使用序号，分割成：

>   ​	已发送且确认收到分组
>
>   ​	已发送未确认分组
>
>   ​	可用未发送分组
>
>   ​	不可用分组（next+N）



N一般叫做窗口，很简单的理由是可以方便对发送方进行流量控制以避免网络传输拥塞。



那么什么时候GBN协议需要响应呢？

>   ​	显然收到了一个ACK是需要发送新的报文组的
>
>   ​	超时的时候就需要回退N步了
>
>   ​	上层调用（也就是应用层操作）



第三种的时候，首先检查是否已经发送了N个数据报，若是则返回窗口已经满了，若否，则产生一个分组再发送。

实际上，现实中应对是的时候，是缓存需要发送的数据，或者使用同步机制（仅当窗口有空闲的时候才可以调用发送数据报函数）



好了，现在再考虑接收方是怎么操作的，收到了数据报分组，自然是需要核对序号是否有缺失的，如果有缺失，就直接丢弃最小序号有缺失之后的所有数据，再请求发送发重传即可。

为了减轻接收方的缓存负担，不是需要的分组序号数据报的时候直接丢弃接收到的数据报。



### 选择重传



GBN协议有一个致命的缺点，就是如果窗口N=1000中，仅有一个数据有问题那么这个数据之后的所有数据报都需要重新传送，这大大浪费了信道资源，降低了信道利用率，为此，我们为了改进就引入了选择重传的协议，也叫做==SR协议==。



这个协议最大的特点就是不会直接丢弃没有接收到的数据报之后的所有数据而是==选择缓存==之后所有接受到数据报分组，直到缺失的数据抵达之后再组成完全的数据报分组，如果没有确认这个数据报分组，==接收窗口==时永远不能向前滑动的。



正是这个原因，==发送窗口==和==接收窗口==并不总是一致的。而且不一致将带来严重的后果，例如：超时重传重复序号无法辨别，分组内重复序号丢失。



>   超时重传会导致无法区分时第一个分组序号还是分组序号中的数据报。
>
>   分组内重复序号也将导致接收方无法识别序号顺序。



如图：

![IMG_1555](C:\Users\wonderfulfaker\Pictures\Camera Roll\IMG_1555.PNG)





那么怎么解决呢？



是的，就是设置一个恰好的窗口大小，通常来说是设置成序号空间大小的一半或者小于它。这样就能极大地避免数据报重复无法识别的情况。



很好，我们现在基本了解了可靠的数据传输机制是如何形成的了，那么需要总结一下：

>   ​	检验和：这个在UDP就已经使用起来的方法，是为了检测传输分组中的比特错误而开发的。
>
>   
>
>   ​	定时器：用于检测超时/重传分组，当数据报超时但未丢失时/接收方发送的ACK丢失时，可能会产生延时事件，这也将使得接收方可能收到多个冗余的数据					报副本。
>
>   
>
>   ​	序号：用于检测数据报分组是否有丢失，也可以用于检测有相同序号的数据报进行冗余区分。
>
>   
>
>   ​	确认：接收方成功收到数据报后返回给发送发的确认信息ACK
>
>   
>
>   ​	否定确认：接收方告诉发送发某个分组数据报没有被正确地接收，通常带有需要发送地分组数据报序号，要求发送发重新发送。
>
>   
>
>   ​	流水线：为了提高信道利用率和节省带宽，所使用的可以连续发送数据报分组的技术。不需要等待接收方返回ACK。
>
>   
>
>   ​	窗口：为了控制发送发的发送速率，防止拥塞，以便于进行拥塞控制所使用的技术。窗口的长度可以根据接收方接收和缓存报文的能力进行确定。





---



### TCP

既然我们已经学习了可靠的数据传输协议是如何构建的，那么就来学习一下最通用的IPV4中的协议TCP（Transmission Control Protocol），中文名：传输控制协议



#### TCP简介



TCP与UDP的区别：



>   ​	TCP最大的特点是面向连接的，UDP并不是，它是非连接的。
>
>   ​	TCP是全双工的，UDP是单向的。
>
>   ​	TCP仅能进行单播，点对点传播，无法像UDP还可以进行多播/广播
>
>   ​	TCP的传输方式是面向报文的，UDP的是面向字节流。
>
>   ​	首部开销不同，TCP可以是20-60字节，UDP仅仅8字节



给每块数据配上一个TCP首部也就形成了==TCP报文段==，结构和UCP报文段是相似的：

>   ​	源端口和目的端口，负责多路复用/分解，也是运输层主要要实现的功能。
>
>   ​	检验和字段

但是也有不同：

>   ​	32bit的序号字段和32bit的确认号字段（用于可靠传输）
>
>   ​	16bit的接收窗口字段（用于流量控制）
>
>   ​	4bit首部长度（TCP首部是变长的，指示何处数据开始）
>
>   ​	选项字段（确认最大报文段又叫MSS）用于调节窗口
>
>   ​	6bit标志字段（用于处理特殊的情况）例如：ACK,URG,FIN,SYN等



![S8FI8~_GMJLH_IZDLGWHJ{G](C:\Users\wonderfulfaker\Pictures\Camera Roll\S8FI8~_GMJLH_IZDLGWHJ{G.png)





最大报文段又叫MSS，在IPV4中最大为536字节一般使用500字节，IPV6中最大为1220字节一般使用1000字节。



---



#### TCP差错恢复机制



而且TCP只确认数据流中起始序号到第一个丢失的序号之间的数据。这也被称为：累计确认。



我们知道IP协议是网络层中不可靠的传输协议，那么要如何在IP协议之上提供一个可靠传输协议TCP呢？



首先我们考虑发送方，有几种需要封装成TCP数据报递交给IP协议：

>   ​	接收到应用层传来的数据
>
>   ​	超时重传
>
>   ​	接收到接收方发送的ACK



那么再考虑接收方，如果数据丢失或超时，会使用什么协议来响应呢？



是GBN协议还是SR协议呢？都不是，因为TCP协议是累积确认的，这与GBN协议很相似，

>   ​	但是在GBN情况下，若仅仅是接收方返回第n分组之后的ACK丢失的话，发送方会重传n，n+1，....。
>
>   ​	但是TCP的重传只会重传一个报文段，就是n，而当n+1的确认报文段在n报文段超时之前抵达的话，TCP甚至不会重传n报文段。



为此，TCP提出了一个修改方案，选择确认，允许TCP接收方有选择的确认失序报文段，而不是累积地确认最后一个正确接收地有序报文段。

这样就形成了TCP差错恢复机制，它是GBN和SR协议地混合体，可以是得接收方地缓存机制效率大幅提高。



---



#### TCP流量控制



首先，接收方应用程序处理数据地能力可能比不上发送方发送数据地速度，这也就直接导致了接收方缓存地空间溢出了，这个时候就需要进行发送方地==流量控制==了，

注意要和IP网络拥塞的情况区分开来，后者叫做==拥塞控制==。两者面向的对象是不同的，前者是对于应用程序提供的服务，后者是对于IP网络层提供的。



也就是服务的对象是上层还是下层的区别。



我们来看看TCP是如何处理这种情况的，TCP提供了一个接收窗口，它可以动态地表示接收方还有多少缓存可用，来进行流量地控制。

因为TCP是全双工的，所以接收窗口可以同时存在于接收方和发送方两端，而且要保证==最后发送的数据 - 最后确认的数据 <= 接收窗口==（rwnd）



---





#### TCP连接管理



==三次握手==



所谓三次握手（Three-Way Handshake）即建立TCP连接，就是指建立一个TCP连接时，需要客户端和服务端总共发送3个包以确认连接的建立。在socket编程中，这一过程由客户端执行connect来触发，整个流程如下图所示：

![WeChat Image_20210405182453](C:\Users\wonderfulfaker\Pictures\Camera Roll\WeChat Image_20210405182453.png)



（1）第一次握手：Client将标志位SYN置为1，随机产生一个值seq=J，并将该数据包发送给Server，Client进入SYN_SENT状态，等待Server确认。

（2）第二次握手：Server收到数据包后由标志位SYN=1知道Client请求建立连接，Server将标志位SYN和ACK都置为1，ack=J+1，随机产生一个值seq=K，并将该数据包发送给Client以确认连接请求，Server进入SYN_RCVD状态。

（3）第三次握手：Client收到确认后，检查ack是否为J+1，ACK是否为1，如果正确则将标志位ACK置为1，ack=K+1，并将该数据包发送给Server，Server检查ack是否为K+1，ACK是否为1，如果正确则连接建立成功，Client和Server进入ESTABLISHED状态，完成三次握手，随后Client与Server之间可以开始传输数据了。

简单来说，就是

1、建立连接时，客户端发送SYN包（SYN=i）到服务器，并进入到SYN-SEND状态，等待服务器确认

2、服务器收到SYN包，必须确认客户的SYN（ack=i+1）,同时自己也发送一个SYN包（SYN=k）,即SYN+ACK包，此时服务器进入SYN-RECV状态

3、客户端收到服务器的SYN+ACK包，向服务器发送确认报ACK（ack=k+1）,此包发送完毕，客户端和服务器进入ESTABLISHED状态，完成三次握手，客户端与服务器开始传送数据。





==四次挥手==



所谓四次挥手（Four-Way Wavehand）即终止TCP连接，就是指断开一个TCP连接时，需要客户端和服务端总共发送4个包以确认连接的断开。在socket编程中，这一过程由客户端或服务端任一方执行close来触发，整个流程如下图所示：

![WeChat Image_20210405184015](C:\Users\wonderfulfaker\Pictures\Camera Roll\WeChat Image_20210405184015.png)

TCP四次挥手.png

由于TCP连接时全双工的，因此，每个方向都必须要单独进行关闭，这一原则是当一方完成数据发送任务后，发送一个FIN来终止这一方向的连接，收到一个FIN只是意味着这一方向上没有数据流动了，即不会再收到数据了，但是在这个TCP连接上仍然能够发送数据，直到这一方向也发送了FIN。首先进行关闭的一方将执行主动关闭，而另一方则执行被动关闭，上图描述的即是如此。

（1）第一次挥手：Client发送一个FIN，用来关闭Client到Server的数据传送，Client进入FIN_WAIT_1状态。

（2）第二次挥手：Server收到FIN后，发送一个ACK给Client，确认序号为收到序号+1（与SYN相同，一个FIN占用一个序号），Server进入CLOSE_WAIT状态。

（3）第三次挥手：Server发送一个FIN，用来关闭Server到Client的数据传送，Server进入LAST_ACK状态。

（4）第四次挥手：Client收到FIN后，Client进入TIME_WAIT状态，接着发送一个ACK给Server，确认序号为收到序号+1，Server进入CLOSED状态，完成四次挥手。



---





#### SYN泛洪攻击



在三次握手过程中，Server发送SYN-ACK之后，收到Client的ACK之前的TCP连接称为半连接（half-open connect），此时Server处于SYN_RCVD状态，

当收到ACK后，Server转入ESTABLISHED状态。



SYN攻击就是Client在短时间内伪造大量不存在的IP地址，并向Server不断地发送SYN包，Server回复确认包，并等待Client的确认，由于源地址是不存在的，因此，Server需要不断重发直至超时，这些伪造的SYN包将产时间占用未连接队列，导致正常的SYN请求因为队列满而被丢弃，从而引起网络堵塞甚至系统瘫痪。



SYN攻击时一种典型的DDOS攻击，检测SYN攻击的方式非常简单，即当Server上有大量半连接状态且源IP地址是随机的，则可以断定遭到SYN攻击了，使用如下命令可以让之现行：



```bash
#netstat -nap | grep SYN_RECV
```



当然，现在也已经拥有了有效的防御系统了，那就是SYNcookie,那么他是如何保护服务器的呢？



>   ​	第一，他不会给一开始的任何接收到的SYN建立半连接，而是生成一个初始TCP序列号，是一个仅仅为目的IP地址和服务器知道的复杂函数。这个初始序列	号被称为cookie。但是服务器不会保存cookie和SYN其他的状态信息表。
>
>   ​	第二,如果客户是合法的，会返回一个ACK报文段，服务器收到后需要验证是否与前面发送的SYN对应，这里需要用到cookie返回的源地址，端口号来运行散列函数来进行检验。
>
>   ​	第三，若检查无误，建立连接。



---





#### 拥塞控制原理



在某段时间，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络性能就要变坏，这种情况就叫做网络拥塞。



在计算机网络中数位链路容量（即带宽）、交换结点中的缓存和处理机等，都是网络的资源。网络资源也具有反馈拥塞信息的功能。

从网络中反馈信息的方式有两种：

>   ​	返回阻塞分组，直接说明我拥塞了
>
>   ​	路由器标记或者更新从发送方留下接收方的分组中的某个字段来指示拥塞的产生，接收方在收到该标记分组后向发送方通知拥塞信息，这个过程只是需要一	个完整的往返时间，延迟较高。



网络中辅助的拥塞控制例子：

>   ​	ATM控制算法，主要是面向虚电路（这个在网络层会学到）的方法来处理分组交换。
>
>   ​	ABR控制算法，是一种弹性的数据传输服务，当网络轻载时，会从分利用空闲的可用带宽；当网络拥塞时，会抑制某些预先确定的最小传输速率的传输。



两个例子都会使用，RM信元（资源管理信元）来提供直接网络反馈和经接收方的网络反馈。如图：



![IMG_1558(20210405-190723)](C:\Users\wonderfulfaker\Pictures\Camera Roll\IMG_1558(20210405-190723).PNG)



RM信元中包含了以下信息：

>   ​	EFCI比特，显式转发拥塞指示比特。设置为1，表示网络拥塞。
>
>   ​	CI和NI比特，RM中有一个CI(拥塞指示)比特和NI（无增长）比特，这两个比特可以被一个拥塞的交换机设置，轻度拥塞设置NI为1，重度拥塞设置CI为1.
>
>   ​	ER设置，每一个RM包含一个两字节的显示速率（Explicit Rate，ER）字段，一个拥塞的交换机也许会降低ER的值，通过这种方式可以取得路径上的MIN支	持速率





---



#### TCP拥塞控制



在某段时间，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络性能就要变坏，这种情况就叫做网络拥塞。



在计算机网络中数位链路容量（即带宽）、交换结点中的缓存和处理机等，都是网络的资源。



若出现拥塞而不进行控制，整个网络的吞吐量将随输入负荷的增大而下降。



当输入的负载到达一定程度 吞吐量不会增加，即一部分网络资源会丢失掉，网络的吞吐量维持在其所能控制的最大值，转发节点的缓存不够大这造成分组的丢失是拥塞的征兆。



==拥塞控制的方法==可以分为两大类：

>   ​	端到端的拥塞控制（对网络行为的观察进行推断），例如：报文段丢失，往返时延
>
>   ​	网络辅助的拥塞控制（网络层构件反馈信息），例如：路由器，交换机返回的信元。





TCP的四种拥塞控制算法



>   ​	1.慢开始（启动）
>   ​	2.拥塞避免（控制）
>   ​	3.快重传
>   ​	4.快恢复



过程：



慢开始是指一开始窗口的大小是指数级增长，直到窗口大小到达设定好的阈值（ssthresh），一般都是设置为窗口大小的一半，即为cwnd/2，则转变为线性增长的模式，也就是逐步+1的方式扩大窗口。如果检查到三个冗余的ACK或则超时，此时TCP将执行一种快速重传，并且进入快速恢复的状态。



通过几张图片来理解这个给过程是怎么实现的：



![WeChat Image_20210405184919](C:\Users\wonderfulfaker\Pictures\Camera Roll\WeChat Image_20210405184919.png)





![WeChat Image_20210405185052](C:\Users\wonderfulfaker\Pictures\Camera Roll\WeChat Image_20210405185052.png)





![WeChat Image_20210405193044](C:\Users\wonderfulfaker\Pictures\Camera Roll\WeChat Image_20210405193044.png)







![WeChat Image_20210405193048](C:\Users\wonderfulfaker\Pictures\Camera Roll\WeChat Image_20210405193048.png)





![WeChat Image_20210405193051](C:\Users\wonderfulfaker\Pictures\Camera Roll\WeChat Image_20210405193051.png)





TCP Reno算法也已经有了许多的变种，其中就有TCP Vegas，基本思想是：

>   ​	在分组丢失发生之前，在源与目的地之间检测路由器中的拥塞。
>
>   ​	当快要检测出分组丢失时，线性地降低发送的速率。（这个时通过RTT来预测地）



---

### 总结



数据报控制协议（DCCP）datagram congestion control protocol,提供了一种低开销，面向报文，类似于UDP地不可靠的无法，但是具有应用程序可选择地拥塞控制形式，该机制可以和TCP兼容，被设想用于流媒体传输。



流控制传输协议（SCTP）stream control transmission protocol,是一种可靠地，面向报文的协议，该协议允许几个不同的应用层次的流复用到单个SCTP连接上，当一台主机与多个网络连接时，SCTP允许数据金国两条出路径传输，允许失序交付，因此一条流的丢失不会影响别的数据流。



TCP友好速率控制协议(TFRCP)  TCP - friendly rate control protocol , 是一种拥塞控制协议而不是运输层的协议，定义了一种拥塞控制机制：

>   ​	能被DCCP等其他运输层协议使用
>
>   ​	为了能够平滑TCP拥塞控制中的锯齿行为（也就是重新起步造成的波动）
>
>   ​	维护一种长期的发送速率以接近TCP合理的速率，使其更加平滑地发送数据。



非常适合IP电话或者流媒体等多媒体应用。



----







## 3.网络层（数据报）



### 简介



运输层依赖于网络层地主机到主机地通信服务，网络层中每一台主机和路由器都构成一个网络层的部分，例如：IP地址，MAC地址等，这也使得网络层是最为复杂的，要构造该层的协议也必将是困难和麻烦的，为此我们需要逐步思考该如何实现网络层之间的通信，先辈们已经提供了两种大的方向：

>   ​	数据报模式
>
>   ​	虚电路模式
>
>   

那么网络层要实现的功能包括哪些呢？

>   ​	网络层的转发（单一路由器从一条链路到另一条链路）
>
>   ​	路由器选择（涉及一个网络的所有路由器）
>
>   ​	连接建立（要求状态信息从源到目的地沿着所选择的路径彼此握手，以便网络层中的数据分组能在传输开始之前建起状态）例如：ATM,帧中继，MPLS



为了深入理解分组转发，我们需要进入路由器的内部观察他的硬件结构和组织，然后再观察英特网中的分组转发，这包括了，网际协议（IP），网络层的编址，IPV4,网络地址转换（NAT），数据报分段，英特网控制报文协议（ICMP）,IPV6。



其后再去了解网络层的路由选择功能，路由选择算法，选择算法的理论，算法类型：

>   ​	链路状态
>
>   ​	距离矢量算法



涉及到因特网自治==系统内部==的路由选择协议，例如：

>   ​	RIP
>
>   ​	OSPF
>
>   ​	IS-IS

和因特网自治==系统之间==的路由选择协议的时候，例如：BGP，是如何理论付诸实践的。



---



### 转发和路由选择



前面有介绍：

>   ​	转发涉及分组在单一的路由器中从一条入链路到一条出链路的传送
>
>   ​	路由选择涉及一个网络的所有路由器，它们经路由选择协议共同交互，以决定分组从源到目的地结点所采用的路径。



其中转发中需要使用到转发表，每台路由器都具有一张转发表，路由器通过检测分组首部字段的值来转发分组，那么==转发表==是怎么判断的呢？



---



#### 转发表



 转发表（FIB）：用于判断基于 IP 包的网络前缀，如何进行转发。对于每一条可达的目标网络前缀，FIB 包含接口标识符和下一跳信息。 FIB 概念上类似于路由表，它维护一份 RIB 表中的转发信息镜像。



但是，转发表可能会因为网络中的变动而产生改变，此时需要改变转发表了，就需要知道路由器中的转发表是如何配置的



首先考虑路由选择算法分为两种类型：

>   ​	集中式（中心点计算，向下传送选择信息）
>
>   ​	分布式 （运行在每一台路由器的算法）



然后区分分组交换机的类别：

>   ​	链路层交换机（基于链路层字段的值）
>
>   ​	其他的交换机：就叫路由器 （基于网络层字段中的值）





---



#### 路由表



然后路由选择算法主要是为了更新路由表的，那么==路由表==是什么呢？



在[计算机网络](https://baike.baidu.com/item/计算机网络/18763)中，**路由表**（routing table）或称**路由择域信息库**（RIB, Routing Information Base），是一个存储在[路由器](https://baike.baidu.com/item/路由器/108294)或者联网计算机中的电子表格（文件）或类数据库。



它分为==静态路由表==和==动态路由表==两种类型，其中静态路由表是不需要用的路由选择算法的：

>   ​	1．[静态路由表](https://baike.baidu.com/item/静态路由表)
>
>   ​	由[系统管理员](https://baike.baidu.com/item/系统管理员)事先设置好固定的路由表称之为静态（static）路由表，一般是在系统安装时就根据网络的配置情况预先设定的，它不会随未来网络结构的改	变而改变。
>
>   
>
>   2．[动态路由表](https://baike.baidu.com/item/动态路由表)
>
>   ​	动态（Dynamic）路由表是[路由器](https://baike.baidu.com/item/路由器)根据网络系统的运行情况而自动调整的路由表。路由器根据[路由选择协议](https://baike.baidu.com/item/路由选择协议)（Routing Protocol）提供的功能，自动学习和	记忆网络运行情况，在需要时自动计算数据传输的最佳路径。



路由表中有什么信息和功能呢？



>   存储着指向特定[网络地址](https://baike.baidu.com/item/网络地址/9765459)的路径（在有些情况下，还记录有路径的路由度量值）。
>
>   
>
>   中含有网络周边的[拓扑](https://baike.baidu.com/item/拓扑/573536)信息。
>
>   
>
>   建立的主要目标是为了实现[路由协议](https://baike.baidu.com/item/路由协议/202634)和[静态路由](https://baike.baidu.com/item/静态路由/100778)选择。



每个路由器中都有一个路由表和[FIB](https://baike.baidu.com/item/FIB)(Forward Information Base)表：路由表用来决策路由，FIB用来转发分组。路由表中有三类路由：

>   ​	链路层协议发现的路由（直接连接的路由）
>
>   ​	静态路由
>
>   ​	动态路由协议发现的路由



路由表中的项有什么呢？

>   ​	每个项的目的字段含有目的网络前缀
>
>   ​	每个项还有附加字段，负责制定网络前缀位数的子网掩码
>
>   ​	下一跳字段（项）代表路由器时，下一跳字段的值使用路由的IP地址



具体的是：

>   destination：目的地址，用来标识IP包的目的地址或者目的网络。
>
>   mask：网络掩码，与目的地址一起标识目的主机或者路由器所在的网段的地址。
>
>   pre：标识路由加入IP路由表的优先级。可能到达一个目的地有多条路由，但是优先级的存在让他们先选择优先级高的路由进行利用。
>
>   cost：路由开销，当到达一个目的地的多个路由优先级相同时，路由开销最小的将成为最优路由。
>
>   interface：输出接口，说明IP包将从该路由器哪个接口转发。
>
>   nexthop：下一跳IP地址，说明IP包所经过的下一个路由器。





---



### 网络服务模型



考虑一下，当运输层向网络层传递一个分组的时候，网络层能够提供哪些特定的服务？



>   ​	确保交付
>
>   ​	具有时延上界的交付



此外，在给定源和目的地之间的分组流 能够提供哪些服务呢？



>   ​	有序分组的交付
>
>   ​	确保最小带宽
>
>   ​	确保最大时延抖动（发送方的ms与接收方的ms一样）
>
>   ​	安全性服务



这些仅仅是网络层能够提供的服务的一部分，还有无数可能的服务变种，因特网几乎是尽力而为的无服务的模型，为此诞生了很多改良的服务模型，如图：



![IMG_1559(20210407-102145)](C:\Users\wonderfulfaker\Pictures\Camera Roll\IMG_1559(20210407-102145).PNG)





其中CBR（constant bit rate），指的是恒定比特率ATM网络服务，一般用于电话通信，音频，视频需要恒定的传输比特率下。

ABR（available bit rate），指的是可用比特率ATM网络服务，最小的信元传输速率是可以得到保证的。



---



### 虚电路和数据报网络



回想一下运输层有TCP,UDP两种传输协议，类似的，网络层也有两种传输的方式，虚电路（VC/virtual - circuit）网络和数据报（datagram - network）网络。

但是他们之间区别还是很大的，包括一下几点：

>   ​	网络层中，两种服务模型是==对====运输层==提供主机到主机的服务 ； 运输层中，是==对应用层==提供进程到进程的服务 。
>
>   ​	网络层中，使用的网络服务模型不是虚电路就是数据报网络。不能如同运输层中改良TCP后可以同时提供两种服务。
>
>   ​	网络层中，不仅仅是在端系统实现服务，还在网络核心——路由器中实现 ； 运输层中的服务仅仅位于网络边缘的端系统中实现。





#### 虚电路



​	虚电路组成：

-   ​	源和目的主机之间的路径（一系列链路和路由器）、VC（virtual circuit）号，沿着该路径的每段链路的号码、以及该路径上每台路由器中的转发表。

    ​	

    一条虚电路的分组将在它的首部携带一个VC号。

    

    一条虚电路在每条链路上可能具有不同VC号，故每台中间路由器必须用一个新的VC号替代每个传输分组的VC 号。该新的VC号从转发表获得。

​	

​	虚电路网络，每台路由器的转发表包括了VC号的转换【入接口，入VC号，出接口，出VC号】。



​	虚电路有三个明显不同的阶段：

>   ​	连接建立
>
>   ​	数据传送
>
>   ​	连接拆除



![20180523215900208](C:\Users\wonderfulfaker\Pictures\Camera Roll\20180523215900208.bmp)



​	无论何时跨越一台路由器创建一条虚电路，转发表就增加一个新表项，因此经过的路径上的路由器都有记录信息。



​	无论何时删除一条虚电路，沿着该路径每个表中的相应项将被删除（路由器必须为进行中的连接维持连接状态信息）。



---



#### 数据报网络



特点有哪些：



>   数据报网络是网络层无链接的服务。
>
>   
>
>   端系统每要发送一个分组，就为该分组加上目的端系统的地址，然后将该分组推进网络。
>
>   
>
>   数据报网路中不维护连接状态信息，但有转发状态信息。
>
>   
>
>   每个路由器使用一个分组的目的地址来转发该分组。
>
>   
>
>   路由器匹配目的地址时，使用最长前缀匹配规则。
>
>   
>
>   转发表大概每1~5分钟由路由算法更新一次。



在路由器上，有两个重要的东西：



>   一个是路由算法，用来确定通过网络的端到端路径；
>
>   另一个是转发表，转发表确定了本路由器如何转发分组。



需要注意的是对于转发表，目的地址是32位的IP地址，那么就有几十亿各IP地址，一个路由器不可能维护一个几十亿的表，对于IPV6则会更加多达到2的64次方，比地球上所有物质加起来还多，所有转发表是按照地址的范围转发的，如图：

![WeChat Image_20210407110116](C:\Users\wonderfulfaker\Pictures\Camera Roll\WeChat Image_20210407110116.png)





既然是按照范围寻址，那么就有一个匹配问题，在数据报网络中采用的是最长前缀匹配优先原则，如图：



![WeChat Image_20210407110621](C:\Users\wonderfulfaker\Pictures\Camera Roll\WeChat Image_20210407110621.png)



上方的数据报走链路 1 ，下方的数据报走链路 2 。



---



### 路由器工作原理



在上面已经了解了一些转发的问题，例如：区域编址，最长前缀匹配问题。那么路由器是如何解决这些问题的呢？



首先考虑路由器的结构有哪些？主要是四个部分：

>   ​	输入端口
>
>   ​	输出端口
>
>   ​	交换结构
>
>   ​	选择处理器



输入端口，输出端口，交换结构这些共同实现了转发功能的硬件，一般来说这些**硬件实现**转发功能被总称为==路由器转发平面==



路由器选择协议，对上线下线连接链路的响应，通过**软件实现**并且在选择处理器上实现的，这种路由器的控制功能一般被总称为==路由器控制平面==。



==转发平面==以**纳秒**时间尺度运行，路由器的==控制功能==在**毫秒或秒**时间尺度上运行。



---



#### 输入端口



​	如图，



![WeChat Image_20210407112228](C:\Users\wonderfulfaker\Pictures\Camera Roll\WeChat Image_20210407112228.png)





1.最左边的**线路端接**功能和**数据链路处理**功能实现了用于各个输入链路的物理层和链路层。



2.输入端口进行的查找功能对路由器的执行是至关重要的。转发表的一份影子副本通常会被存放在**每个输入端口**，从而避免了集中式处理的瓶颈。



3.由于查找需要在纳秒级执行，因此不仅需要硬件执行查找，而且需要对大型查找表使用超出简单线性搜索的技术。同时，必须对内存访问时间给予特别关注，使用 DRAM 和 SRAM 来设计。



4.通过查找确定了某分组的输出端口，该分组就能进入交换结构。某些设计中，一个分组可能在进入交换结构时被暂时阻塞。此时，被阻塞的分组必须要在输入端	口处排队，并等待稍后被及时调度以通过交换结构。



5.此外，还需要完成一些其他工作，包括并不限于：

1.  检查分组的版本号、校验和以及寿命字段，并且重写后两个字段
2.  更新用户网络管理的计数器



---



##### DRAM,SRAM



静态随机访问存储器（Static Random Access Memory - SRAM）和动态随机存取存储器(Dynamic Random Access Memory -DRAM)



>   所谓的“静态”，是指这种存储器只要保持通电，里面储存的数据就可以恒常保持。
>
>   
>
>   相对之下，动态随机存取存储器（DRAM）里面所储存的数据就需要周期性地更新。
>
>   
>
>   当电力供应停止时，SRAM储存的数据还是会消失（被称为volatile memory），这与在断电后还能储存资料的ROM或闪存是不同的。
>
>   
>
>   SRAM是比DRAM更为昂贵，但更为快速、非常低功耗（特别是在空闲状态）。因此SRAM首选用于带宽要求高，或者功耗要求低，或者二者兼而有之。SRAM比起DRAM更为容易控制，也更是随机访问。由于复杂的内部结构，SRAM比DRAM的占用面积更大。
>
>   
>
>   DRAM拥有非常高的密度，单位体积的容量较高，因此成本较低。DRAM也有缺点，DRAM也有访问速度较慢，耗电量较大的缺点。与大部分的[随机存取存储器](http://zh.wikipedia.org/wiki/隨機存取記憶體)（RAM）一样，由于存在DRAM中的数据会在电力切断以后很快消失，因此它属于一种易失性存储器（volatile memory）设备。









---





#### 交换结构



交换结构位于一台路由器的核心部位。交换可以用多种方式进行，如经内存交换、经总线交换、经互联网络交换。

如图所示：

![IMG_1560(20210407-121622)](C:\Users\wonderfulfaker\Pictures\Camera Roll\IMG_1560(20210407-121622).PNG)





1.经内存交换：



>   一个分组到达输入端口时，该端口先通过中断方式向路由选择处理器发出信号。
>
>   
>
>   于是该分组从输入端口被复制到处理器内存中。
>
>   
>
>   路由选择处理器从其首部中提取目的地址，在转发表中查找输出端口，并将该分组复制到输出端口的缓存中。
>
>   
>
>   不能同时转发两个分组，即使它们有不同的端口号，因为经过共享系统总线一次仅能执行一个内存读/写。



现代路由器很多使用内存交换，但是目的地址的查找和分组存储交换进适当的内存存储位置是由==输入线路卡==来处理的，早期的是：通过==路由选择器==





2.经总线交换：



>   输入端口经一根共享总线将分组直接传送到输出端口，不需要路由选择处理器的干预：让输入端口为分组预先计划一个交换机内部标签（首部），指示本地输出端口，使分组在总线上传送和传输到输出端口。
>
>   
>
>   该分组能由所有输出端口收到，但只有与该标签匹配的端口才能保存该分组。然后标签在输出端口被去除。一次只有一个分组能够跨越总线。



因为一次只能一个分组通过唯一地总线，故而速率受到了极大的限制。





3.经互联网络交换：



>   如上图，每条垂直的总线和水平的总线在交叉点处交叉，交叉点通过交换结构控制器能够在任何时候开启和闭合。
>
>   
>
>   若来自两个不同输入端口的两个分组其目的地为相同的输出端口，则一个分组必须在输入端等待。因为在某个时刻经给定总线仅有一个分组能够发送。



纵横式的交换总线网络可以做到并行地转发多个分组。





---





#### 输出端口



除了不需要查找和拆解之外，与输入端口是完全相反地操作，排队——协议，封装——线路连接



取出存放在输出端口缓存中的分组并将其发送到输出链路上。



包括选择和取出排队的分组进行传输，执行所需的链路层和物理层传输功能。



如图：



![WeChat Image_20210407122730](C:\Users\wonderfulfaker\Pictures\Camera Roll\WeChat Image_20210407122730.png)





---



#### 路由选择处理器



无论在中低端还是高端路由器中，[CPU](https://baike.baidu.com/item/CPU)都是路由器的心脏。通常在中低端路由器中，CPU负责交换路由信息、[路由表](https://baike.baidu.com/item/路由表)查找以及转发[数据包](https://baike.baidu.com/item/数据包)。



在[高端路由器](https://baike.baidu.com/item/高端路由器)中，通常包转发和查表由ASIC芯片完成，CPU只实现[路由协议](https://baike.baidu.com/item/路由协议)、计算路由以及分发路由表。



ASIC芯片：



>   ASIC芯片技术所有接口模块（包括控制模块）都连接到一个矩阵式背板上，通过ASIC芯片到ASIC芯片的直接转发，可同时进行多个模块之间的通信；
>
>   
>
>   每个模块的缓存只处理本模块上的输入输出队列，因此对[内存芯片](https://baike.baidu.com/item/内存芯片/3736671)性能的要求大大低于共享内存方式。
>
>   
>
>   总之，交换矩阵的特点是访问效率高，适合同时进行多点访问，容易提供非常高的带宽，并且性能扩展方便，不易受CPU、总线以及内存技术的限制。



由于技术的发展，路由器中许多工作都可以由硬件实现（专用芯片）。CPU性能并不完全反映路由器性能。路由器性能由路由器吞吐量、时延和路由计算能力等指标体现。



---



#### 路由器丢包



在输入和输出端口都能够形成分组队列。随着这些队列的增长，路由器的缓存空间最终将会耗尽，此时如果有新的分组到达，会导致**丢包 (packet loss)**。



一般有两种情况会造成丢包：



输出端口队列导致丢包

输入端口队列导致丢包



那么具体是怎么丢包地呢？



>   假设输入和输出线路的速率都是 每秒R个分组，有 N 个输入端口和 N 个输出端口，交换结构的速率足够快。每个线路上的分组都有相同的固定长度，分组以同步的方式到达输入端口，且每个分组都被转发到同一个输出端口。
>
>   
>
>   这种情况下，向输出链路发送一个分组的时间内，将有 N 个分组到达该输出端口。这 N 个到达的分组必须排队传输到输出链路上。随着时间的推移，排队的分组数量将耗尽输出端口可用内存，最终导致丢包。
>
>   ​          
>
>   如果交换结构不能快到使所有到达的分组无时延地通过它传送，则在输入端口也将出现分组排队。因为到达的分组必须加入输入端口队列中，以等待通过交换结构传送到输出端口。                                                    



应该怎么处理呢？



1.  输出端口排队时，在输出端口的一个分组调度程序必须在这些排队的分组中选出一个来发送，如==先来先服务调度==FCFS，==加权公平排队==WFQ。

    

2.  若没足够内存来缓存一个入分组：要么丢弃到达的分组（==弃尾==），要么删除一个会多个已排队的分组来为新到的分组腾出空间。

    

3.  在某些情况下，在缓存填满前便丢弃一个分组，以便向发送方提供一个==拥塞信号==。

    

4.  分组丢弃和标记策略有如==主动队列管理==AQM算法，随机==早期检测算法==RED是一种最广泛研究和实现的AQM算法。

    

5.  RED中为输出队列维护加权平均值，若平均队列长度小于最小阈值，则当分组到达时，该分组被接纳进队列，若队列满或平均队列长度大于最大阈值，当分组到达时被标记或丢弃，若当分组到达时，平均队列长度在最小阈值和最大阈值之间，则该分组以某种概率被标记或丢弃。





---



### 转发和编址



在学习转发和编址之前需要了解到网络层都有哪些协议控制着这些操作。



首先是路由器选择协议



还有IP协议和ICMP协议



具体如图：



![IMG_1561(20210407-124650)](C:\Users\wonderfulfaker\Pictures\Camera Roll\IMG_1561(20210407-124650).PNG)





---





#### 数据报格式



既然要转发和编址，自然需要了解我们需要转发地东西，在网络层中地分组被称为数据报，那么它的语法和语义，构成是怎样的呢？



以IPV4为例，如图

![IMG_1562(20210407-125049)](C:\Users\wonderfulfaker\Pictures\Camera Roll\IMG_1562(20210407-125049).PNG)





①、版本号：这4比特规定了数据报的IP协议版本。通过查看版本号，路由器能够确定如何解释IP数据报的剩余部分。不同的IP版本使用不同的数据报格式。



②、首部长度：因为一个 IPv4 数据报可包含一些可变数量的选项(这些选项包括在IPv4 数据报首部巾) ，故需要用这4比特来确定IP数据报中数据部分实际从哪里开始。大多数IP数据报不包含选项，所以一般的IP数据报具有20字节的首部。



③、服务类型TOS：使不同类型的IP数据报(例如，一些特别要求低时延、高吞吐量或可靠性的数据报)能相互区别开来。



④、数据报长度：这是 IP 数据报的总氏度(首部加上数据) ，以字节计。因为该字段长为 16 比特，所以 数据报的理论最大长度为 65535 字节 然而，数据报很少有超过 15 字节的。



⑤、标识、标志、片偏移：这三个字段与所谓IP分片有关，但，新版本的 IP(IPv6)不允许在路由器上对分组分片



⑥、寿命TTL：段用来确保数据报不会永远(如由于长时间的路由选择环路)在网络中循环。每当数据报由一台路由器处理时，该字段的值减1，TTL字段减为0，则该数据报必须丢弃。



⑦、协议：该字段仅在一个IP数据报到达其最终目的地才会有用。该字段值指示了IP数据报的数据部分应交给哪个特定的运输层协议。在 IP 数据报中的协议号所起的作用，类似于运输层报文段中端口号字段所起的作用。协议号是将网络层与运输层绑定到一起的粘合剂，而端口号是将运输层和应用层绑定到一起的粘合剂。



⑧、首部检验和：首部检验和用于帮助路由器检测收到的IP数据报中的比特错误。首部检验和是这样计算的:将首部中的每2个字节当作一个数，用反码运算对这些数求和。



⑨、源和目的IP地址：当某源生成一个数据报时，它在源IP字段中插入它的IP地址，在目的IP地址字段中插人其最终目的地的地址。通常源主机通过DNS查找来决定目的地址。



⑩、选项：选项字段允许IP首部被扩展。首部选项意味着很少使用，因此决定对每个数据报首部不包括选项字段中的信息，这样能够节约开销。然而，选项的可能存在的确是件复杂的事，因为数据报头长度可变，故不能预先确定数据字段从何处开始。而且还因为有些数据报要求处理选项，而有些数据报则不要求，故导致一台路由器处理一个IP数据报所需的时间变化很大，这些考虑对于高性能路由器和主机上的IP处理来说特别重要。由于这样或那样的原因，在IPv6首部已去掉了IP选项。



11.数据(有效载荷)：在大多数情况下，IP数据报中的数据字段包含要交付给目的地的运输层报文段(TCP/UDP)然而，该数据宇段也可承载其他类型的数据，如ICMP报文。



---



##### IP数据报分片



因为不是所有的链路层协议都是可以承受同样长度的数据报分组，而且路径上所使用的链路层协议也不可能一成不变在。



例如：	因特网中最大的长度为：1500+字节，局域网中的是：500+字节



链路层所能承载的最大数据量叫做：==最大传送单元==（MTU）



那么要如何解决这个问题？



很简单，再将其==分片==，变成更小的数据分组来传输即可，但是这样也就加大了路由器的负担，而且运输层都希望收到没有分片的数据分组，所以就把分片重新组装的功能放到端系统再进行。



但是IP协议是不可靠的运输，所以一定会有一个或者多个永远都无法到达端的分片，为了使端系统继续运行，会将最后一个片的标识为0，以确定已经接收到最后一个片。



**简单地讲，就是把一个大的IP数据报切分为符合当前协议的MTU的数据报，并且数据报的标志除了最后一个为0，其余都是1。其中首部字节为20，其余的MTU-20字节均为数据字节。偏移量为字节数8**。



分片的缺点也特别的明显：

>   ​	使得路由器和端系统也更加复杂
>
>   ​	为不法分子进行攻击提供了更多的手段，安全性受到了威胁



为此，IPV6从根本上废除了分片，简化了IP分组的处理，使得IP不太容易受到攻击。

---



#### 编址



##### 记法



主机与链路一般只有一个接口，所以一个主机一般只有一个IP地址作为索引；



而一台路由器与多个链路相连作为十字路口，所以每一个接口对应一个IP地址作为索引。



每个IP地址长度为32比特(等价为4字节)，因此总共有个可能2^32^的IP地址。



由于2^32^近似地表示10^3^，故容易看出约有40亿个可能的IP地址。



这些地址一般按所谓点分十进制记法书写，即地址中的每个字节用它的十进制形式书写，各字节间以句号(点)隔开。



例如，考虑IP地址193.32.216.9，193是该地址第一个8比特的十进制等价数，32是该地址第二个8比特的十进制等价数，依次类推。因此，地址193.32.216.9 的二进制记法是:

11000001 00100000 11011000 00001001



在全球因特网中的每台主机和路由器上的每个接口，必须有一个全球唯一的lP地址(在NAT后面的接口除外)。然而，这些地址不能随意地自由选择。一个接口的IP地址的一部分需要由其连接的子网来决定。

---



##### 子网



那么子网和子网掩码又是什么呢？是如何构成的呢？

如图：



![IMG_1563(20210407-132544)](C:\Users\wonderfulfaker\Pictures\Camera Roll\IMG_1563(20210407-132544).PNG)



**简单地讲，就是，没一个字节可以代表一个分支，不同的分支构成了一颗四层的树，而每一个分支可以看做一个小的子网，一般是最左边最大，越往右越下层。子网中无需通过路由器就能够物理上互相到达**。



**即当子网掩码为20的时候，外界只需要知道他的前20位，即他能转发到符合前20位的IP地址，而不需要关心后12位的具体内容，即不需要知道他能转发到的具体地址**。



一般来说子网掩码只能使用A/B/C三类，分别是/8，/16，/24bit，这也就是使得可能造成较多的剩余子网空间的浪费。



为此诞生了DHCP，动态主机配置协议。



---

##### 岛



还有路由器之间的链路会形成岛，如图：



![IMG_1564(20210407-132807)](C:\Users\wonderfulfaker\Pictures\Camera Roll\IMG_1564(20210407-132807).PNG)



---



##### 动态主机配置协议



DHCP允许主机自动获取(被分配)一个IP地址。



网络管理员能够配置DHCP，以使某给定主机每次与网络连接时能得到一个相同的IP地址，或者某主机将被分配一个临时的IP地址,该地址在每次与网络连接时也许是不同的。



具有的特点：



>   除了主机IP地址分配外，DHCP还允许一台主机得知其他信息，例如它的子网掩码、它的第一跳路由器地址(常称为默认网关)与它的本地DNS服务器的地址。
>
>   
>
>   DHCP还广泛地使用于住宅因特网接入网与无线局域网中，允许其中的主机频繁地加入和离开网络。
>
>   
>
>   当主机加入或离开时，DHCP服务器要更新其可用IP地址表。
>
>   
>
>   每当一台主机加入时，DHCP服务器从其当前可用的地址池中分配一个任意的地址给它;每当一台主机离开时，其地址便被收回这个池中。（即插即用）



**简单地讲，就是定义了一个ip地址池，其前缀与子网掩码相同，后缀随机进行分配。每当一个主机进入时，自动给予一个IP地址；当一个主机离开时，回收该IP地址。可分配IP地址范围是：子网地址-广播地址**。



---



##### 网络地址转换（NAT）



NAT使能路由器对于外部世界来说甚至不像一台路由器NAT路由器对外界的行为反过来就如同一个具有单一IP地址的单一设备。



下图中，所有离开家庭路由器流向更大因特网的报文都拥有一个源IP地址138.76.29.7，且所有进入家庭的报文都拥有同个目的回地址138.76.29.7。



![IMG_1565(20210407-134637)](C:\Users\wonderfulfaker\Pictures\Camera Roll\IMG_1565(20210407-134637).PNG)









即把内部私有网络地址翻译成合法网络IP地址的技术。能够改变本地网络中的设备地址，而不必通知外部。



本地网络中的设备不显式地可寻址、由外部所见 (增强安全性)。简单地讲，就是把一个家庭网络的对外IP进行了改变。从本质上讲，NAT使能路由器对外界隐藏了家庭网络的细节。

使用在NAT路由器上的一张NAT转换表，并且在表项中包含了端口号及其IP地址。



NAT的问题：



>   由于使用了端口号，很多技术专家认为这是不安全的。应该使用IPV6来解决IP不够用的问题，而非使用NAT。
>
>   
>
>   还有个问题是，阻碍了P2P的应用程序，双方主机端都在NAT后方时将会很麻烦，需要应用程序进行中继处理。
>
>   
>
>   单方在NAT后方时可以使用中间对等方主机进行绕过，在与之通信。



---



#### 因特网控制报文协议（ICMP）



被主机和路由器用来彼此沟通网络层的信息（打小报告的）。



ICMP最典型的用途是差错报告。ICMP通常被认为是IP的一部分，但从体系结构上讲它是位于IP之上的，因为ICMP报文是承载在IP分组中的。



这就是说，lCMP报文是作为IP有效载荷（数据）承载的，就像TCP/UDP报文段作为IP有效载荷被承载那样。（ICMP被IP运载     ；   UDP/TCP被IP运载）



类似地，当一台主机收到一个指明上层协议为ICMP的IP数据报时，它分解出该数据报的内容给ICMP，就像分解出一个数据报的内容给TCP/UDP一样。



ICMP报文有一个**类型字段**和一个**编码字段**，并且包含引起该ICMP报文首次生成的IP数据报的首部和前8字节内容。



ICMP报文示例如图：



![IMG_1566(20210407-135713)](C:\Users\wonderfulfaker\Pictures\Camera Roll\IMG_1566(20210407-135713).PNG)



---



#### IPV6



由于新的子网和IP结点以惊人的增长率连到因特网上(并被分配唯一的IP地址)，32比特的IP地址空间即将用尽。为了应对这种对大IP地址空间的需求，开发了一种新的IP协议，即IPv6。



IPV6的数据报格式如图：



![IMG_1567(20210407-140033)](C:\Users\wonderfulfaker\Pictures\Camera Roll\IMG_1567(20210407-140033).PNG)







**版本号(version)**

  不同的IP协议版本使用不同的数据报格式。

**通信量等级(Traffic Classes)**

  使得源节点和路由器能够识别IPv6信息包的优先级。与IPv4服务类型TOS字段含义类似。

**流标签(Flow Label)**

  标记那些需要IPv6路由器**特殊处理**(如一种非默认服务质量或实时服务)的信息包顺序（ VIP的功效）。

**有效负载长度(Payload Length)**

  定长40字节数据报首部后面的字节数量，包括扩展报头和负载数据，即数据报长度  40。

**下一个首部(Next Header)**

  当IPv6没有扩展报头时，该字段的作用和IPv4的上层协议字段一样。当含有扩展报头时，该字段的值即为第一个扩展报头的类型。

**跳限制(Hop Limit)**

  转发数据报的每台路由器对该字段的值减1，若减为0则丢弃该数据报。

**源和目的IP地址(Source/Destination Address)**

**数据(Data)**

  当数据报到达目的地时，该有效载荷就从IP数据报移出，并交给下一个首部字段中指定的协议。







首部格式40字节有助于提高处理/转发速率。首部变化以促进QoS。

IPV6 地址：IPv6地址长度为128位

IPv6较IPv4的区别：

①、检查和：完全去除以减小每跳的处理时间  

②、选项：允许，但在首部之外，由“下一个首部” 字段指示	

③、新版本的ICMP	（分组丢失路由器直接请求源主机重发）



IPv4到IPv6的迁移：IPv6向后兼容（通过隧道的方法），可以发送、路由和接收IPv4数据报。但IPv4确不能处理IPv6数据报



**隧道**：IPV6路由器之间的IPV4路由器的集合。



---



### 路由选择算法



主机通常直接与一台路由器相连接，该路由器即为该主机的默认路由器(defaultrouter) ，又称该主机的第一跳路由器(first-hop router)每当主机发送一个分组时，该分组被传送给它的默认路由器。



源主机的默认路由器称作源路由器(sourcerouter) ,目的主机的默认路由器称作目的路由器(destination router)。



一个分组从源主机到目的主机的路由选择问题显然可归结为**从源路由器到目的路由器的路由选择问题**。

 

路由选择算法可分为：



-   **全局式**路由选择算法：所有路由器**掌握完整的网络拓扑和链路费用**信息，例如==链路状态(LS)路由算法==

    

-   **分散式**路由选择算法；路由器只掌握**物理相连的邻居以及链路费用**，例如==距离向量(DV)路由算法==

    

又可以分为：



-   ==静态路由算法==：**手工配置**、路由**更新慢**、优先级高

    

-   ==动态路由算法==：路由**更新快**、定期更新、**及时响应链路费用或网络拓扑变化** ；

    ​							但是存在==震荡==(oscillations / 可能出现在任何使用拥塞或基于时延的链路测度的算法中)，==选择循环==等问题的影响



还可以分为：



-   ==负载敏感算法==：链路费用会动态地变化以反映出底层链路的当前拥塞水平。如果当前拥塞的一条链路与高费用相联系，则路由选择算法趋向绕开该拥塞链路来选择路由。

    

-   ==负载迟钝算法==：当今的因特网路由选择算法（如RIP 、OSPF和BGP) 都是负载迟钝的，因为某条链路的费用不明显地反映其当前/最近的拥塞水平。





---





#### 链路状态(LS)路由算法



LS 算法中，网络拓扑和所有链路开销都已知，在实践中可以使用**链路状态广播**算法来完成，通过结点广播就可以使所有结点得到该网络完整的、统一的视图。



具体过程是：



>   所有结点(路由器)通过链路状态广播掌握网络拓扑和链路费用，拥有相同信息
>
>   
>
>   只计算自己的转发表计算从一个源结点到达所有其他结点的最短路径，经过k次迭代后，得到到达k个目的结点的最短路径假设链路费用是该链路承载的通信量。



链路状态路由选择算法可以用Dijksua算法实现；对于 Dijkstra 算法可以使用**堆结构**对其进行强化，使其时间复杂度缩小到 **O(nlogn)**。







---



#### 距离向量(DV)路由算法





DV 算法是一种迭代、异步和分布式的算法。



**分布式**体现于算法的流程，是要每个结点都从一个或多个直接连接的邻居接收信息，通过对信息的计算，再把结果通告给邻居。



**迭代**体现于算法对于上述的过程，需要一直持续到邻居之间没有信息需要交换位置。**异步**体现于不需要所有的节点统一进行操作，而是当收到邻居发来的信息进行操作即可。



---





#### Bellman-Ford 方程



DV 算法的原理使用了 Bellman-Ford 方程，具体内容如下。（感觉就是动态规划的算法）



结合我们的情景讲一下每个参数，“c(x,v)” 表示 x 到邻居 v 的开销，dv(y) 表示从邻居 v 到目的地 y 的开销，我们需要在 x 的所有邻居中获得最小值。



>   dx(y) = minv{c(x,v) + dv(y)}



Bellman-Ford 方程为 DV 算法的与邻居的通信提供了理论基础。



简单地说，也就是结点获得最短路径的下一跳，并且将该信息写入转发表中。这时我们也给出距离向量的定义，向量所表示的信息是 x 在 N 中到其他所有结点 y 的开销估计向量。



>   Dx = [Dy: y ∈ N]













----





#### 震荡



什么是震荡呢？



路由选择算法由于拥塞敏感而产生了**振荡**。也就是经过多此LS算法之后，大多的甚至所有的路由器走沿着同一条路径进行传播，此时会产生拥塞。





如何解决这个问题呢？



>   如果修改度量的基准，使得路由选择算法不按照或者减轻按照所承载的流量来判断的话，显然不行，因为路由选择就是要避开拥塞的路径。
>
>   
>
>   比较好的做法是**确保并非所有路由器同时运行 LS 算法**，也就是路由器以相同的周期，不同的时机来运行算法。
>
>   
>
>   同时这又会引发**自同步**的问题，也就是算法的执行时间随着运行会慢慢趋于同步，此时可以让路由器发送链路通告的时间随机生成，就可以打消自同步。



---







#### 算法的比较



LS算法和DV算法的比较：



>   -   **报文复杂性**
>
>       
>
>   LS 算法要求每个结点都知道网络中每条链路的费用，要发送O(|N|*|E|)个报文。而且无论何时一条链路的费用改变时，必须向所有结点发送新的链路费用。
>
>   
>
>   DV算法要求在每次迭代时，在两个直接相连邻居之间交换报文。当链路费用改变时,DV 算法仅当在新的链路费用导致与该链路相连结点的最低费用路径发生改变时，才传播已改变的链路费用。
>
>   
>
>   -   **收敛速度**
>
>       
>
>   LS算法的实现是一个要求O(|N|*|E|)个报文的O(|N|^2)算法；时间复杂度和我们熟悉的 Dijkstra 算法相同，但是会有震荡的问题
>
>   
>
>   DV 算法收敛较慢，且在收敛时会遇到路由选择环路，还会遭遇==无穷计数==（对于路由器彼此之间认为对方可到达而出现环路的情况，我们称之为**无穷计数**），主要原因是好消息传播快，坏消息传播慢，使得容易造成选择环路。
>
>   
>
>   >   一般使用==毒性逆转==来解决无穷计数问题，但是不能完全解决。
>   >
>   >   
>   >
>   >   （这种手法的思想是若一个结点到某目的的最小开销路径需要通过某个邻居，则通告给该邻居节点到达目的的开销为 ∞）
>
>   
>
>   
>
>   -   **健壮性**。
>
>       
>
>   如果一台路由器发生故障、行为错乱或受到破坏时
>
>   
>
>   LS算法：路由器能够向其连接的一条链路广播不正确费用。作为LS广播的一部分，一个结点也可损坏或丢弃它收到的任何LS广播分组。但是每个LS结点都仅计算自己的转发表。因此路由计算在某种程度上是分离的，提供了一定程度的健壮性。
>
>   
>
>   DV算法：一个结点可向任意或所有目的结点通告其不正确的最低费用路径。因此一个不正确的结点计算值会扩散到整个网络。





---



### 路由选择协议

---



#### IGP（内部网关协议）

IGP（Interior Gateway Protocol，内部网关协议）是在一个自治网络内网关（主机和路由器）间交换路由信息的协议。路由信息能用于网间协议（IP）或者其它网络协议来说明路由传送是如何进行的。Internet网被分成多个域或多个自治系统。一个域（domain）是一组主机和使用相同路由选择协议的路由器集合，并由单一机构管理。IGP协议包括 RIP、OSPF、IS-IS、IGRP、EIGRP（思科私有协议）等。



IGP的选路原则：

-   优先级
-   开销
-   负载均衡



---



##### RIP协议



RIP协议是一种内部网关协议（IGP），底层是贝尔曼福特算法，是一种动态路由选择协议，用于自治系统（AS）内的路由信息的传递。



RIP协议基于距离矢量算法（DistanceVectorAlgorithms），使用“跳数”(即metric)来衡量到达目标地址的路由距离。



这种协议的路由器只关心自己周围的世界，只与自己相邻的路由器交换信息，范围限制在15跳(15度)之内，再远，它就不关心了。所以rip只适用于小区域。



Rip协议运行在 UDP 协议之上，使用 520 端口，使用 224.0.0.9 作为组播地址，向外组播路由信息



工作原理：RIP通过广播UDP报文来交换路由信息，每30秒发送一次路由信息更新。RIP提供跳跃计数(hopcount)作为尺度来衡量路由距离，跳跃计数是一个包到达目标所必须经过的路由器的数目。如果到相同目标有二个不等速或不同带宽的路由器，但跳跃计数相同，则RIP认为两个路由是等距离的。RIP最多支持的跳数为15，即在源和目的网间所要经过的最多路由器的数目为15，跳数16表示不可达。



---





##### OSPF协议



OSPF(Open Shortest Path First开放式最短路径优先）是一个内部网关协议IGP，用于在单一自治系统内决策路由。



是对链路状态路由协议的一种实现，隶属内部网关协议（IGP），故运作于自治系统内部。SPF算法用作生成最短生成树。



OSPF分为OSPFv2和OSPFv3两个版本,其中OSPFv2用在IPv4网络，OSPFv3用在IPv6网络。



OSPFv2是由RFC 2328定义的，OSPFv3是由RFC 5340定义的。与RIP相比，OSPF是链路状态协议，而RIP是距离矢量协议，它选择路由的度量标准是带宽，延迟。



适合在大中区域，目前最流行的路由协议。Rip协议使用 224.0.0.5 作为组播地址，向外组播路由信息。DR监听 224.0.0.6 端口来获取从DOther发来的LSA信息，ospf协议号 89



---



##### IS-IS协议



IS-IS（Intermediate System-to-Intermediate System，中间系统到中间系统）路由协议最初是ISO（the International Organization for Standardization，国际标准化组织）为CLNP（Connection Less Network Protocol，无连接网络协议）设计的一种动态路由协议



---



##### EIGRP协议



**EIGRP协议**：它是思科私有路由协议，高级距离矢量路由协义，适用大中型网络



---



#### EGP（外部网关协议）



**EGP**（Exterior Gateway Protocol，外部网关协议）是AS之间使用的路由协议,其目前只有一个协议--BGP协议



---





##### BGP（边界网关协议）



BGP(Border Gateway Protocol)边界网关协议是运行于 TCP 上的一种自治系统的路由协议。



 BGP 是唯一一个用来处理像因特网大小的网络的协议，也是唯一能够妥善处理好不相关路由域间的多路连接的协议。



 BGP 构建在 EGP 的经验之上。 BGP 系统的主要功能是和其他的 BGP 系统交换网络可达信息。



网络可达信息包括列出的自治系统（AS）的信息。这些信息有效地构造了 AS 互联的拓朴图并由此清除了路由环路，同时在 AS 级别上可实施策略决策。



BGP属于EGP(外部网关路由协议)，可以实现自治系统间无环路的域间路由。



BGP是沟通Internet广域网的主用路由协议，例如不同省份、不同国家之间的路由大多要依靠BGP协议。



BGP可分为IBGP（Internal BGP）和EBGP（External BGP）。



BGP的邻居关系（或称通信对端/对等实体）是通过人工配置实现的，对等实体之间通过TCP（端口179)会话交互数据。BGP路由器会周期地发送19字节的保持存活keep-alive消息来维护连接（默认周期为30秒）。在路由协议中，只有BGP使用TCP作为传输层协议





---



### 广播与多播路由选择



两台主机之间通信的方式：



广播：广播是指在IP子网内广播数据包，所有在子网内部的主机都将受到这些数据包。广播意味着网络向子网每一个主机都投递一份数据包，不论这些主机是否乐于接收该数据包。所以广播的使用范围非常小，只在本地子网内有效，通过路由器和交换机网络设备控制广播传输。



多播：也叫组播，组播在发送者和每一接收者之间实现点对点网络连接。如果一台发送者同时给多个的接收者传输相同的数据，也只需复制一份的相同数据包。它提高了数据传送效率，减少了骨干网络出现拥塞的可能性。



---



#### 广播路由选择算法



1.1 最简单的的发送方式: 向每个目的地发送一个副本



效率低,每个发送的副本都将通过开头那段链路传输,每个目的地的地址都必须被发送方知晓,不太可能.



1.2 更有效的方式(**泛洪**)



源节点仅向第一跳发送副本,然后由第一跳向第二跳发送副本,以此类推



1.3 **无控制洪泛**



实现广播的最显而易见的技术；



具体是：源节点向所有邻居发送副本,邻居接收到后向除了源节点外的所有邻居转发副本出现的问题



广播风暴:如果节点图是有环的就可能导致副本无限循环



1.4 **受控洪泛**: 解决广播风暴的方法



避免广播风暴的关键是每个结点明智地选择何时洪泛分组，何时不洪泛分组



解决方法



**序号控制洪泛**( sequence- number- controlled flo。由19)



源结点将其地址(或其他唯一的标识符)以及广播序号 (broadcast sequence number) 放入广播分组，再向它的所有邻居发送该分组 。



每个结点维护它已经收到的、复制的和转发的源地址和每个广播分组的序号列表 。



当结点接收到一个广播分组时，它首先检查该分组是否在列表中 。 如果在，丢弃该分组;如果不在，复制该分组并向该结点的所有邻居转发(除了接收到该分组从其的那个结点) 。



**反向路径转发** (Reverse Path Forwarding, RPF)



当一台路由器收到具有给定源地址的广播分组时,仅当该分组到达的链路正好是位于它自己的返回其源的最短单播路径上,才向其他出链路转发报文,否则丢弃注意到 RPF 不使用单播路由选择以实际将分组交付给目的地，它也不要求路由器知道从它自己到源的完整最短路径 。



仅需要知道在它到发送方的单播最短路径上的下一个邻居;它仅使用这个邻居的身份以决定是否洪泛一个接收到的广播分组 。



1.5 **生成树广播**: 冗余广播分组的消除





很明显,在广播的时候会出现一个节点接收几个副本的情况

流程：



首先对网络结点构造出一棵生成树。

当一个源结点要发送一个广播分组时，它向所有属于该生成树的特定链路发送分组 。

接收广播分组的结点则向在生成树中的所有邻居转发该分组(其接收该分组的邻居除外)。

生成树不仅消除了冗余的广播分组，而且一旦合适，该生成树能够被任何结点用于开始广播分组。

注意到一个结点不必知道整棵树;只需要知道它在 G 中的哪些邻居是生成树的邻居 。



**基于中心的方法**( cenler-based approach)



与生成树方法相关的复杂性主要是生成树的生成和维护 。



这里仅考虑一种简单的算法-基于中心的算法



中心节点也被称为汇合点或核



结点则向中心结点单播加入树( tree- join) 报文 。



图例:基于中心构造一颗生成树



实践中的广播算法：在实践中，广播协议被用于应用层和网络层 。



---



#### 多播路由选择算法



2.1 多播分组仅被交付给网络结点的一个子集



2.2 **多播中的两个问题**





>   如何标识多播分组的接收方
>
>   
>
>   怎样为发送到这些接收方的分组编址



2.3 **间接地址(D类地址)**



在因特网体系结构中,多播数据报使用间接地址来编址



用一个标识来表示一组接收方，寻址到该组的分组副本被交付给所有与该组相关联的多播接收方，且该组使用这个单一标识符 。



这种表示一组接收方的单一标识就是一个D类多播地址 。



与一个 D 类地址相关联的接收方小组被称为一个多播组 (multicast group)



例如若4 台主机(显示为深色)与多播组地址 226.17.30.197 相关联，则它们将接收所有寻址到该多播地址的数据报 。



2.4 **多播组的一些问题**





>   一个组是如何形成，又如何终结的呢?
>
>   
>
>   如何选择组地址?新主机如何加入某个组(要么作为发送方，要么作为接收方) ?
>
>   
>
>   任何主机都能加入一个组(向该组发送或从族组接收)或者组成员资格会受到限制吗?
>
>   
>
>   如果有限制，由谁限制?作为网络层协议的一部分，一个组成员知道其他组成员的标识吗?
>
>   
>
>   网络结点相互之间如何进行交互，以向所有组成员交付一个多播数据报呢?





2.5 **因特网组管理协议**





IGMP 为一台主机提供了手段，让它通知与其相连的路由器:在本主机上运行的 一个应用程序想加入一个特定的多播组 。



由于 IGMP 的交互范围被局限在主机与其相连的路由器之间，显然需要另一种协议来协调遍及因特网内的多播路由器(包括相连的路由器) ,以便多播数据报能路由到其最终目的地 。



后一个功能是由网络层多播路由选择算法完成因此因特网中的网络层多播是由两个互补的组件组成的:IGMP 与多播路由选撑协议。





2.6 **多播路由选择算法**





多播路由选择的目标就是发现一棵链路的树，这些链路连接了所有具有属于该多播组的相连主机的路由器 。



于是多播分组将能够沿着这棵树从发送方路由到所有属于该多播树的主机 。



两种方法来确定多播路由选择树

>   使用一棵组共享树的多播路由选择：构建单一的、共享的路由选择树
>
>   
>
>   使用一棵基于源的树的多格路由选择：为多播组巾的每个源构建一棵多播路由选择树





==剪枝(== pruning)



一台接收到多播分组的多播路由器，如它无加人该组的相连主机，则它向其上游路由器发送一个图例:剪柑匠文。 



如果一台路由器从它每个下游路由器收到剪枝报文，则它就能向上游转发一个剪枝报文。





2.7 **因特网中的多播路由选择**





第一个用于因特网中的多播路由选择协议是==距离向量多播路由选择协议==





使用最为广泛的因特网多播路由选择协议是协议无关的多播 (Proloco! Inclepenclent Mu1Licasl ,PIM) 路由选择协议。



该协议明确辨识**两种多播分发**情形：



>   稀疏模式：在源特定多播中，仅允许单一发送方向多播树中发送流量，大大简化了树的构造和维护 。
>
>   
>
>   稠密模式：在稠密模式( dense mode)RFC 3973中,多播组的成员位置分布稠密;这就是说,在该区域内的许多或大多数路由器需要参与到多播数据报路由选择过程之中。PIM稠密模式是一种洪泛与剪枝反向路径转发技术,类似于 DVMRP的思想。









---







## 4.数据链路层（数据帧）



### 简介



很常见问题，当网络层的报文段抵达数据链路层的时候我们会有如下的疑问：



>   ​	分组是如何通过构成端到端通信路径的各段链路的
>
>   ​	在单段链路传输时，数据报是如何封装进链路层成为数据帧的
>
>   ​	不同的链路能够采用不同的链路协议吗
>
>   ​	广播链路中传输碰撞是如何解决的
>
>   ​	链路层有编址吗
>
>   ​	链路层编址如何和网络层的编址一起运行的呢
>
>   ​	交换机和路由器有哪些差异



这些都将会是我们需要学习的知识。



首先要知道，链路层中有两种截然不同的链路层信道类型：



>   ​	**广播信道**：
>
>   ​	一般用于有线局域网，卫星网，混合光纤同轴电缆（HFC）接入王忠的多台主机，此时多主机与信道连接需要==媒体访问协议==（MAC）来协调帧传输。
>
>   ​	某些情况也会使用==中心控制器==来协调。
>
>   ​	
>
>   ​	**点对点信道**：
>
>   ​	一般用于长距离链路连接两台路由器，用户主机与临近以太网交换机之间的链路，协调点对点的协议显然会比较简单，使用PPP协议，点到点协议。
>
>   ​	该协议也适用于光纤链路的高速点到点帧传输。



有以下的链路层基本概念：

>   ​	运行链路层协议的任何设备均称为==节点==（node），例如：主机，路由器，交换机，WIFI接入点
>
>   ​	沿着通信路径连接相邻节点的通信信道称为==链路==



有一个很形象的类比，在人们选择去旅游的时候，可能会报旅行社，然后旅行社负责选择最便捷的路径抵达目的地，想要抵达目的地会有多个运输区段，期间所用的交通工具也是多样的，但是人们还是各自安全抵达了目的地。



游客——数据报

这里面的旅行社——路由选择协议

每个运输区段——链路

多种交通工具——链路层协议



链路层会提供哪些服务呢？

>   ​	成帧（帧的结构由链路层协议确定）
>
>   ​	链路接入（使用==媒体访问控制协议（MAC）==相当于不存在的协议，既无论何时只要链路空闲，发送方都能够发送帧）
>
>   ​	可靠交付（保证无差错地经过链路层移动每一个网络层数据报，通常时使用**确认和重传**取得的）
>
>   ​	差错检验和纠正（链路层的差错检测更加复杂，通过硬件实现，它能够做到比差错检测不能做到的准确确定出错的位置。**能找错更精准**）



链路层是在哪里实现的呢？

>   ​	主体部分：==网络适配器==（network adapter），也叫==网络接口卡==（network interface card）NIC。
>
>   ​	网络适配器的核心是：链路层控制器，它实现了链路层的几乎所有的服务，包括但不限于：成帧，链路接入，差错检测。
>
>   ​	因此链路层许多功能是**硬件实现**的。
>
>   ​	在还有部分链路层的功能是由**软件组件**实现的,例如：**组装链路层寻址信息**，**激活控制器硬件**等，这一般是位于端系统中，例如个人电脑。
>
>   ​	接收端中，链路层软件还**响应控制器终端**，**处理差错条件**，**数据报向上传递**给网络层



**综上，链路层是硬件和软件的结合体，是协议栈中软件和硬件交接的地方。**



---



### 差错检测和纠正技术



我们进行通信时的网络信道并不总是可靠的。



为了增加可靠性，我们需要在传输数据后加上一些冗余的码字。



如果接收方能够通过它们直接纠正错误，那么我们就称之为==纠错码==（Error Correcting Code）。



如果接收方仅能通过它们发现错误，而真正纠正错误的过程需要通知发送方进行重传，那么我们就称之为==检错码==（Error Detecting Code）。





**比特级差错检测和纠正**，既对从一个节点发送到另一个物理上连接的邻近节点的链路层帧中的比特损伤进行检测和纠正。



使用**差错检测和纠正**（Error-Detection and -Correction,DTC）比特来增强数据,需要保护不仅仅是网络层传输下来的信息还包括链路帧首部中的各种信息。



即使使用DTC还是有可能出现未检出比特差错（undetected bit error），所以需要一个可靠的DTC，但是越可靠开销也就越大，那么需要怎么做呢？







先研究一下差错检测的三种技术吧：

>   ​	奇偶校验（基本思想）
>
>   ​	检验和方法（多用于运输层）
>
>   ​	循环冗余检测（多用于适配器）



---





#### 奇偶校验



基本原理：

>   无论数据位多少位，校验位只有一位。
>
>   数据位和校验位一共所含的1个数为奇数，称为奇校验。
>
>   数据位和校验位一共所含的1个数为偶数，称为偶校验。



**数据是如何校验的**？



我们可以知道，在数据传输之前，我们会求一次校验位，传输后，会求一次校验位，那么，在奇偶校验中，我们通过比较这两个校验位是否相同，一般是采用异或的方式。

若结果为1，则说明有奇数个错误。

结果为0，则说明正确或者偶数个错误。



**（结果就是对比之后需不需要再加1，不需要就是加0就是正确的或者内部发生了偶数个错误）**



---





##### 奇校验



奇校验： 如果给定一组数据位中 1 的个数是偶数，那么奇校验位就置为 1，使得总的 1 的个数保持奇数不变。
举例解释：

| 数据（1的个数） | 奇校验      |
| --------------- | ----------- |
| 0000 0011（2）  | 0000 0011 1 |
| 0000 0100（1）  | 0000 0100 0 |
| 0111 1111（7）  | 0111 1111 0 |

​	



因为是奇校验，所以当二进制数中1的个数为偶数个时，需要添加1（可以在前面加也可以在后面）来将二进制中1的个数补为奇数个；

当二进制数中1的个数为奇数个时，就不需要做任何操作。

在我们知道了奇校验之后，我们不知道应该把校验位加在哪里，这就需要我们审题目了。本道题中时对于每个字符进行操作，我们会通过举例发现：



3的奇校验输出为10110011

a的奇校验输出为01100001

字符3的ASCII码的十进制为：51，转化为二进制数0011 0011

字符a的ASCII码的十进制为：97，转化为的二进制数0110 0001



ASCII码使用7位二进制数（剩下的1位二进制为0）来表示所有的大写和小写字母，数字0 到9、标点符号。



总结来看，该处的字符按照ACSII码对应的十进制数转化为二进制进行奇校验，最高位奇校验校验位。





---



##### 偶校验



偶校验英文简写EVEN，当实际数据中“1”的个数为偶数的时候，这个校验位就是“0”，否则这个校验位就是“1”，这样就可以保证传送数据满足偶校验的要求。



在接收方收到数据时，将按照偶校验的要求检测数据中“1”的个数，如果是偶数个“1”，表示传送正确，否则表示传送错误。





| 数据（1的个数） | 偶校验   |
| --------------- | -------- |
| 0100101（3）    | 01001011 |
| 0100100（2）    | 01001000 |
| 1010001（3）    | 11010001 |





---



同步传输常用奇校验，异步传输常用偶校验。



为什么呢？



>   认真研究奇校验和偶校验的实现电路不难发现，**偶校验位的产生直接对待发送的数据依次做异或运算就可以得到，而产生奇校验位还要在偶校验电路的输出取非**，相对而言，产生奇校验位的代价高，速度也相对慢（慢一个逻辑门的时延）。
>
>   
>
>   同步传输是多位数据在同步控制信号的控制下同时从发送端发到接收端，对于同步传输，如果被传输的数据为全0，此时采用奇校验时，接收端至少会收到1个1，
>
>   
>
>   很容易判断确实有传送发生，如果采用偶校验，此时收发双方都是0，判断的开销变大了，综合起来还是奇校验更加划算。
>
>   
>
>   而异步传输奇偶校验都可，那么就用了开销小的偶校验。





---



##### 二维奇偶校验



单维度的奇偶校验局限性还是有的，例如：差错一般都是突发的形式集中在一起的，也就是说可能在单维度奇偶数校验的情况下无法准确的校验出错误。



这个时候就引入了二维的奇偶校验，将比特数据集中的D分为了d个比特分别放置于i行，j列的二维数组中，再对产生的i+j+1个奇偶比特进行校验。



只有当行和列的奇偶校验都对上的时候才表示该行列无差错。



无差错的二维偶数校验如图：

|        | 一列 | 二列 | 三列 | 四列 | 五列 | 校验列 |
| ------ | ---- | ---- | ---- | ---- | ---- | ------ |
| 一行   | 1    | 0    | 1    | 0    | 1    | 1      |
| 二行   | 1    | 1    | 1    | 1    | 0    | 0      |
| 三行   | 0    | 1    | 1    | 1    | 0    | 1      |
| 校验行 | 0    | 0    | 1    | 0    | 1    | 0      |



有差错的二维偶数校验如图：



|        | 一列 | 二列  | 三列 | 四列 | 五列 | 校验列 |
| ------ | ---- | ----- | ---- | ---- | ---- | ------ |
| 一行   | 1    | 0     | 1    | 0    | 1    | 1      |
| 二行   | 1    | ==0== | 1    | 1    | 0    | ==1==  |
| 三行   | 0    | 1     | 1    | 1    | 0    | 1      |
| 校验行 | 0    | ==1== | 1    | 0    | 1    | 0      |





**二维奇偶校验也能够检测一个分组中的两个比特差错，但是不能纠正。**





接收方检测和纠正差错的能力被称为==前向纠错==，（forward error correction，FEC），该技术常常用于CD,回放设备中，它可以单独使用也可以配合链路层的ARQ技术一起应用。







---





#### 检验和方法                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              



原理：

将数据的字段作为d比特数据被作为一个k比特整数的序列处理，一个简单检验和方法就是将这k比特整数加起来，再将所得到和作为差错检验比特。



具体步骤：

>   ​	[1]二进制反码求和，就是先把这两个数取反，然后求和，如果最高位有进位，则向低位进1。
>
>   　[2]另外，先取反后相加与先相加后取反，得到的结果是一样的。因此实现代码都是先相加，最后再取反。



一般来说都是作为16比特的整数对待再求和，例如：

>   ​	IP校验和：IP首部。
>
>   　ICMP校验和：ICMP首部+ICMP数据；
>
>   　UDP、TCP校验和：首部+数据+12个字节伪首部(源IP地址、目的IP地址、协议、TCP/UDP包长)。



再将和的反码形成后装入报文段首部，抵达目的地之后拆解的时候在进行校验。



如果接受的数据的和取反码，结果全为1比特的话说明传输正确，若有一个比特是0，说明有差错，一般协议栈会直接抛弃该数据包。











---



#### 循环冗余检测（🔻）



现如今的计算机网络中广泛应用的差错检测技术是基于==循环冗余检测==(Cyclic Redundancy Check,CRC)编码,CRC编码也叫做多项式编码，为什么呢？



因为该编码能够能够将要发送的比特串看作是系数为0和1的一个**多项式**（需要程序猿自己选择测试），对比特串的操作被解释为多项式算术。



---





###### 基本原理



CRC和海明校验类似，也是**有效信息（**n位）+**校验信息**（k位），需要满足N=n+k≤2k-1（奇数）



循环冗余校验码由信息码n位和校验码k位构成。k位校验位拼接在n位数据位后面，n+k为循环冗余校验码的字长，又称这个校验码（n+k,n）。



==冗余码==(**校验信息**)就是所谓的CRC（如何计算？在数据流末尾补CRC长度[**多项式的幂指数**]的0，然后做除法得到的余数就是了。）



n位信息位可以表示成为一个报文多项式M(x)，最高幂次是x^n-1^。



约定的生成多项式G(x)是一个k+1位的二进制数，最高幂次是x^k^。



将M(x)乘以x^k^，即左移k位后，除以G(x)，得到的k位余数就是校验位。这里的除法运算是模2除法，即当部分余数首位是1时商取1，反之商取0。然后每一位的减法运算是按位减，不产生借位。



**总结一下**：



我们把数据流看作一个被除数，同时约定了一个除数，把通过计算获得一段对应的CRC码字。



 然后呢，计算过程中的除法有点特殊，是==模2除法==（除法运算的过程中不计算其进位）。



这个**生成多项式**（也就是除数）的选择是非常有讲究的，如果你的多项式选择很愚蠢，那么很可能你的检查范围可能只在最后几位。



循环冗余校验码的**特点**：



**理论上可以证明循环冗余校验码的检错能力有以下特点：**

**①可检测出所有奇数位错；**

**②可检测出所有双比特的错；**

**③可检测出所有小于、等于校验位长度的突发错。**



---



###### 例子



说了那么多，不如来个例子：



![image-20210410234036286](C:\Users\wonderfulfaker\AppData\Roaming\Typora\typora-user-images\image-20210410234036286.png)



![image-20210410220855527](C:\Users\wonderfulfaker\AppData\Roaming\Typora\typora-user-images\image-20210410220855527.png





![image-20210410221424511](C:\Users\wonderfulfaker\AppData\Roaming\Typora\typora-user-images\image-20210410221424511.png)





**下面有两个多项式，M（x）代表发送信息的多项式，G（x）代表校验位信息**



![image-20210410221509292](C:\Users\wonderfulfaker\AppData\Roaming\Typora\typora-user-images\image-20210410221509292.png)



上面两个式子所代表的二进制吗根据多项式每项的系数得出



![image-20210410221525258](C:\Users\wonderfulfaker\AppData\Roaming\Typora\typora-user-images\image-20210410221525258.png)



**为什么是要在信息的二进制码上加3个0，是根据右边式子的最高次幂是3，所以左边的式子乘以2的3次方**

1001 = 9 ，相当于 9 ❌ 8 = 72

而1001000 二进制数转化后刚好是 72







![image-20210410221700393](C:\Users\wonderfulfaker\AppData\Roaming\Typora\typora-user-images\image-20210410221700393.png)





**再将上面的两个二进制数做模二除法**





![image-20210410221616536](C:\Users\wonderfulfaker\AppData\Roaming\Typora\typora-user-images\image-20210410221616536.png)



**这里有一个规则，每一步得出的二进制数将抹掉一位，此时如果它的首位是0，那么除数就商0，如果是1，就商1,得出下一个被除数。**



![image-20210410221739392](C:\Users\wonderfulfaker\AppData\Roaming\Typora\typora-user-images\image-20210410221739392.png)

**当除尽的时候，就是余数**



![image-20210410222103087](C:\Users\wonderfulfaker\AppData\Roaming\Typora\typora-user-images\image-20210410222103087.png)



**循环冗余校验码就是这样的出来的**



![image-20210410230117848](C:\Users\wonderfulfaker\AppData\Roaming\Typora\typora-user-images\image-20210410230117848.png)



**上图是黄色的是发送塔，蓝色的是接收塔，发送方和接收方的一个约定是G（x），（两方都知道）**



![image-20210410230130553](C:\Users\wonderfulfaker\AppData\Roaming\Typora\typora-user-images\image-20210410230130553.png)



**如果接收方收到的信息不能整除检验码（也就是余数不是0），就说明信息有错，反之如上**



---



###### 多项式的版本



下面展示常用CRC版本：

| **名称**    | **多项式**                                                   | **表示法**  | **应用举例**                                                 |
| ----------- | ------------------------------------------------------------ | ----------- | ------------------------------------------------------------ |
| CRC-8       | X8+X2+X+1                                                    | 0X107       |                                                              |
| CRC-     12 | X12+X11+X3+X2+X+1                                            | 0X180F      | telecom systems                                              |
| CRC-16      | X16+X15+X2+1                                                 | 0X18005     | Bisync, Modbus, USB, ANSI X3.28, SIA DC-07, many others; also known as CRC-16 and CRC-16-ANSI |
| CRC-CCITT   | X16+X12+X5+1                                                 | 0X11021     | ISO HDLC, ITU X.25, V.34/V.41/V.42, PPP-FCS                  |
| CRC-32      | X32+X26+X23+X22+X16+X12+X11+X10+X8+X7+X5+X4+X2+X+1           | 0x104C11DB7 | ZIP, RAR, IEEE 802 LAN/FDDI, IEEE 1394, PPP-FCS              |
| CRC-32C     | X32+X28+X27+X26+X25+X23+X22+X20+X19+X18+X14+X13+X11+X10+X9+X8+X6+1 | 0x11EDC6F41 | iSCSI, SCTP, G.hn payload, SSE4.2, Btrfs, ext4, Ceph         |











---



### 多路访问链路和协议



网络链路有两种类型，==点对点链路==和==广播链路==。



**点对点链路**很好理解的是点对点链路是单点传输的，例子：PPP传输协议，高级数据链路控制（HDLC）。



**广播链路**是能够让多个发送点和接收点都连接到相同的单一的共享的广播信道上。例如：局域网络，以太网。



但是协调多个发送点和接收点对一个共享的广播信道访问顺序这就需要一个的解决方案了，这就是**多路访问问题**。



类似于会议中讨论也有领导的发言顺序，而控制这个顺序的就是==多路访问协议==（multiple access protocol，MAP）。



因为所有的节点都能够传输帧，所以必定存在几个几点同时传输帧，那么如果一个节点同时接收到多个帧，这就叫做==碰撞==。



而且，产生**碰撞**的帧大概率是比特数据都混合在一起了，必须要丢弃该数据帧，这也就造成了信道资源的浪费。



所以，这也就更加需要设计优秀的**多路访问协议**，目前已经实现了几十多种多路访问协议了，他们都能划分为三大类别：



>   ​	信道划分
>
>   ​	随机接入
>
>   ​	轮流协议



理想情况下的多路访问协议希望信道能够有的特性有：



在MAX速率为 R bps 的广播信道



>   ​	仅有一个节点发送时，有信道的最大速率吞吐量 R bps。
>
>   ​	
>
>   ​	有M个节点要发送数据时，每个节点的吞吐量为 R / M bps ， 不是要求所有节点总是该速率，而是在特定的时间间隔内有该**平均速率**。
>
>   
>
>   ​	协议是分散的，不会因为某个主节点故障而导致整个系统奔溃。
>
>   
>
>   ​	协议是简单的，实现不昂贵。









---





#### 信道划分协议



有三种用于所有共享信道节点之间的广播信道宽带划分技术：



>   ​	时分多路复用（TDM）
>
>   ​	频分多路复用（FDM）
>
>   ​	码分多址复用（CDMA）



假设一个支持N个节点的信道且信道的传输速率是R bps。



**时分多路复用（TDM）**：TDM将时间划分为时间帧，并进一步划分每个时间帧为N个时隙，然后把每个时隙分配各N个结点中的一个，无论何时有结点在有分组要发送时，他在循环的TDM帧中指派给他的时隙内传输分组比特。



优点：TDM消除了碰撞个且非常公平：每个结点在每个帧时间内得到了专用的传输速率R/Nbps的平均速率。



缺点：首先，结点被限制于R/Nbps的平均速率，即使当它是唯一有分组要发送的结点时。其次，结点必须总是等待他在传输序列中的轮次 ，即使他是唯一一个有帧要发送的结点。



**频分多路复用（FDM）**：FDM将R bps信道划分为不同的频段（每个频道具有R/N带宽）并把每个频率分配给N个结点中的一个。



FDM具有和TDM同样的优点和缺点：它避免了碰撞，在N个结点之间公平地划分了带宽。但是他也限制了一个结点只能使用R/N的带宽，即使当他是唯一一个有分组要发送的结点时。



**码分多址（CDMA）**：CDMA对每一个结点分配一种不同的编码，然后每个结点用它唯一的编码来对它发送的数据进行编码。如果精心选择这些编码，就能做到使不同的结点同时传输，并且他们各自相应的接收方仍能正确接收发送方编码的数据，而不在乎其他结点的干扰传输。







---



#### 随机接入协议



在随机接入协议中，一个传输结点总是以信道的全部速率（即R bps）进行发送。当有碰撞时，涉及碰撞的每个结点反复地重发它的帧，到该帧无碰撞地通过为止。但是当一个结点经历一次碰撞时，他不必立刻重发该帧。相反，它在重发该帧前等待一个随机时延。涉及碰撞的每个结点独立地选择随机时延。



**简单说就是，碰撞后，发送节点选个恰当的时间点再重新发送，而不是一直重新发送。**



有随机接入协议例子：**ALOH协议**和**载波侦听多路访问协议（CSMA）**



---





##### **时隙ALOHA**



具体流程：



>   ​	结点有一个新帧要发送时，等到下一个时隙开始并开始在该时隙传输整个帧
>
>   ​	没有碰撞，成功传输该帧，不需要考虑重传。
>
>   ​	有碰撞，结点在时隙结束之前检测到该碰撞，结点以概率 p 在后续的每个时隙重传该帧，知道可以无碰撞地传出去。 



其中，以概率p重传，是指某结点有效地投掷一个有偏倚的硬币，硬币正面时间对应着重传，而重传出现的概率为p。 硬币反面事件对应着“跳过这个时隙，在下个时隙再掷硬币”



**ALOHA**



时隙ALOHA协议要求所有的结点同步他们的传输，以在每个时隙开始时开始传输。



而ALOHA协议是非时隙、完全分散的协议。



在纯ALOHA中，当一帧首次到达，结点立刻将该帧完整的传输进广播信道。如果一个传输的帧在一个或多个传输经历了碰撞，这个结点将==立即==（在完全传输完它的碰撞帧后）以概率p传输该帧，或者以概率1-p在另一个帧时间等待。



**纯ALOHA协议的最大效率（1/2e）只有时隙ALOHA（1/e）的一半。**这就是完全分散的ALOHA协议所要付出的代价。



最大效率：成功一次传输地概率。





---





##### 载波侦听多路访问协议（CSMA）





==载波侦听==（先听）：一个结点在传输前先听信道，如果来自另一个结点的帧正向信道上发送，结点则等待直到检测到一小段时间没有传输，然后开始传输。



既然都听了为什么还会产生碰撞呢？



原因是每个监听检测都需要端到端，这之间是有时延地，叫做：==信道传播时延==。所有结点也不是同时监听的，所以总会有时差导致碰撞。



具有**碰撞检测**的载波侦听多路访问（CSMA/CD）



==碰撞检测==（再观）：当一个传输结点在传输时一直在侦听此信道，如果它检测到另一个结点正在传输干扰帧，它就停止传输，在重复“侦听-当空闲时传输”循环之前等待一段随机时间。



CSMA/CD发送数据帧流程图



![20170313195043842](C:\Users\wonderfulfaker\Pictures\Camera Roll\20170313195043842.png)



在以太网以及电缆网络多路访问协议中有一个减少碰撞的算法：



**二进制指数后退算法**



碰撞结点数量较少时，时间间隔较短，当碰撞结点数量较大时，时间间隔较长。



二进制指数后退算法是指当传输一个给定帧时，在该帧经历了一连串的n次碰撞后，结点随机地从

![20190325085021584](C:\Users\wonderfulfaker\Pictures\Camera Roll\20190325085021584.png)



中选择一个K值。因此，一个帧经历的碰撞越多，K的时间间隔越大。



**效率：**



CSMA/CD效率：当有大量结点，且每个结点有大量的帧要发送时，帧在信道中无碰撞地传输的那部分时间在长期运行时间中所占的==份额==。



其中**dprop**表示信号能量在任意两个适配器之间传播所需的最大时间。**dtrans**表示传输一个最大长度的以太网帧的时间



![20190325084434169](C:\Users\wonderfulfaker\Pictures\Camera Roll\20190325084434169.png)



---



#### 轮流协议



多路访问协议的两个理想特性是：



1.当只有一个结点活跃时，该结点具有R bps的吞吐量 

2.当有M个结点活跃时，每个活跃结点的吞吐量接近R/M bps。



ALOHA和CSMA只满足第一个特性。而轮流协议能够满足两个特性。



轮流协议中比较重要的两个协议是**轮询协议**和**令牌传递协议**



**轮询协议**：要求这些结点之一要被指定为主结点。主结点以循环的方式轮询每个结点。特别是，<u>主结点告诉每个结点能够传输的帧的最多数量</u>。



优点：轮询协议<u>消除了困扰随机接入协议的碰撞和空时隙</u>，这使得轮询取得的效率高得多。



缺点：

第一个缺点是引入了轮询时延，即同时一个结点“它可以传输”所需的时间（只有一个结点时使得速率小于R bps）。<u>玩转盘的时候等他转到你</u>。

第二个缺点是如果主结点故障，整个信道都变得不可操作。**单节点故障**



**令牌传递协议**：一个称为令牌的小的特殊帧在结点之间以<u>某种固定的次序传递</u>。当一个结点收到令牌时，仅当它有一些帧要发送时，他才持有这个令牌。否则，他立即向下一个结点转发该令牌。



优点：令牌传递是分散的，并有很高的效率。

缺点：如果一个结点故障，则会导致整个信道崩溃。或者如果一个结点偶然忘记了释放令牌，则必须调用某些恢复步骤使令牌返回到循环中来。











---



### 交换局域网



交换机是如何转发链路层帧通过交换机网络的。



首先，讨论链路层寻址，然后学习以太网协议，考察链路层交换机的工作方式，交换机是如何构建大规模的局域网的。



---



#### 链路层寻址和ARP



主机和路由器不仅仅是具有网络层的地址（IP），还具有链路层地址（MAC），为什么呢？



这就是本节需要学习的，此外还有==地址解析协议==（ARP）等着我们去探索。



---



##### MAC地址



实际上并不是主机或者路由器具有链路层地址，而是他们的==适配器（网络接口）==具有。



因此，网格网络接口的主机和路由器具有多个与之相关联的链路层地址。



链路层地址还可以叫做：**LAN地址，MAC地址，物理地址**。



对于大多数的局域网而言，MAC地址长度为6字节，共有**2^48^个**可能的MAC地址。



通常使用**十六进制**表示。每个字节被标示为一对十六进制数。



尽管MAC地址被设计为永久的，但是可以使用软件改变一块适配器的MAC地址是可行的。



目前是IEEE负责管理分配MAC地址空间，做法是：前24比特固定，后24位唯一生成一个组合。



当某个发送适配器要让局域网上<u>所有其他适配器接收并处理</u>它打算发送的帧的时候，需要在该帧的目的地址字段插入一个==特殊的MAC广播地址==。







---

##### 地址解析协议



因为存在IP地址和MAC地址，所以需要在它们之间转换，这就是==地址解析协议==（Address Resolution Protocol，ARP）。



①**ARP（Address Resolution Protocol）即地址解析协议， 用于实现从 IP 地址到 MAC 地址的映射，即询问目标IP对应的MAC地址**。



②在网络通信中，主机和主机通信的数据包需要依据OSI模型从上到下进行数据封装，当数据封装完整后，再向外发出。所以在局域网的通信中，不仅需要源目IP地址的封装，也需要源目MAC地址的封装。



③一般情况下，上层应用程序更多关心IP地址而不关心MAC地址，所以需要通过ARP协议来获知目的主机的MAC地址，完成数据封装。





**【ARP协议字段解读】**

Hardware type ：硬件类型，标识链路层协议

Protocol type： 协议类型，标识网络层协议

Hardware size ：硬件地址大小，标识MAC地址长度，这里是6个字节（48bti）

Protocol size： 协议地址大小，标识IP地址长度，这里是4个字节（32bit）

Opcode： 操作代码，标识ARP数据包类型，1表示请求，2表示回应

Sender MAC address ：发送者MAC

Sender IP address ：发送者IP

Target MAC address ：目标MAC，此处全0表示在请求

Target IP address： 目标IP





---





###### 单播





举个具体的例子：



![v2-482e369fa6a8c4246af0164fbc69e2fc_1440w](C:\Users\wonderfulfaker\Pictures\Camera Roll\v2-482e369fa6a8c4246af0164fbc69e2fc_1440w.jpg)



我们给PC1指令-"ping ip2"，这就告知了目的IP，此时PC1便有了通信需要的源目IP地址，但是PC1仍然没有通信需要的目的MAC地址。**这就好比我们要寄一个快递，如果在快递单上仅仅写了收件人的姓名（IP），却没有写收件人的地址（MAC），那么这个快递就没法寄出，因为信息不完整。**



那么，现在PC1已经有了PC2的IP地址信息，如何获取到PC2的MAC地址呢？此时，ARP协议就派上用场了。



![v2-482e369fa6a8c4246af0164fbc69e2fc_1440w](C:\Users\wonderfulfaker\Pictures\Camera Roll\v2-482e369fa6a8c4246af0164fbc69e2fc_1440w.jpg)



通过第三和第四步骤，我们看到PC1和PC2进行了一次ARP请求和回复过程，通过这个交互工程，PC1便具备了PC2的MAC地址信息。



接下来PC1会怎么做呢？在真正进行通信之前，PC1还会将PC2的MAC信息放入本地的【**ARP缓存表**】，表里面放置了IP和MAC地址的映射信息，例如 IP2<->MAC2。接下来，PC1再次进行数据封装，正式进入PING通信，如下==>



![v2-27582d8469224d8a28ee148cf3543e5e_1440w](C:\Users\wonderfulfaker\Pictures\Camera Roll\v2-27582d8469224d8a28ee148cf3543e5e_1440w.jpg)





**小结：**



经过上面6个步骤的处理，PC1终于把数据包发送出去了，之后便可以进行正常的通信了。



看到了吧，ARP的功能和实现过程是如此的简单：它在发送方需要目标MAC地址的时及时出手，通过"一问一答"的方式获取到特定IP对应的MAC地址，然后存储到本地【**ARP缓存表**】，后续需要的话，就到这里查找。



既然是"缓存"表，意味着它有**时效性**，并且如果电脑或者通信设备重启的话，这张表就会**清空**；



也就是说，如果下次需要通信，又需要进行ARP请求。在我们的windows/macos系统下，可以通过命令行"**arp -a**"查看具体信息=>



---



###### 广播



然而实际上的网络并不只是两台主机之间的通信，局域网中可能有几十甚至数百台的主机，还可能是通过有线或者无线的方式连接的，这个时候需要找到主机2要怎么办呢？



这时，ARP协议就需要采用以太网的"广播"功能：将请求包**以广播的形式**发送，交换机或WiFi设备（无线路由器）收到广播包时，会将此数据发给同一局域网的其他所有主机。



那么，什么是广播？对于初学者而言，我们只需要知道，大部分的广播包，它们有一个共同特征：**二层封装时目的MAC是全f（ffff.ffff.ffff）或三层封装时目的IP是全1（255.255.255.255）**。可以这样更方便的记住：目的地址最大的，就是广播。



那么广播是如何实现的呢？看一看图理解：



![v2-2485a31a69987ced88931c4a876bc4b3_1440w](C:\Users\wonderfulfaker\Pictures\Camera Roll\v2-2485a31a69987ced88931c4a876bc4b3_1440w.jpg)





根据上图我们看到，PC1发送的请求广播包同时被其他主机收到，然后PC3和PC4收到之后（发现不是问自己）则丢弃。**而PC2收到之后，根据请求包里面的信息（有自己的IP地址），判断是给自己的，所以不会做丢弃动作，而是返回ARP回应包。**



ARP请求是通过广播方式来实现的，那么，PC2返回ARP回应包，是否也需要通过广播来实现呢？答案是否定的。**大部分网络协议在设计的时候，都需要保持极度克制，不需要的交互就砍掉，能合并的信息就合并，能不用广播就用单播，以此让带宽变得更多让网络变得更快。**



因为广播包中是有发送主机的IP地址，MAC地址等信息的，所以会存储到缓存表，然后直接单播传输请求信息给发送主机。



**小结：**ARP协议通过"一问一答"实现交互，但是"问"和"答"都有讲究，"问"是通过广播形式实现，"答"是通过单播形式。



---



**ARP到底是链路层还是网络层？**



**协议到底所属哪一层，可以从应用/功能来考虑，也可以从层次/包封装来考虑。**

以ARP协议为例，它的功能最终是获取到MAC信息，服务于链路层，从这点考虑，ARP是链路层协议；但是从层次来看，ARP基于Ethernet协议，IP协议基于Ethernet协议，它们在Ethernet协议里面有独立的Type类型，前者是0x0806，后者是0x0800，既然ARP和IP协议"平起平坐"，那么IP是网络层，ARP难道就不是网络层？



**小结：**基于功能来考虑，ARP是链路层协议；基于分层/包封装来考虑，ARP是网络层协议。（此方法对于ICMP协议同样管用）







---



#### 以太网



###### 基本概念



以太网是全球使用最广泛的==局域网技术==，以至于好多人都以为以太网就是我们所说的网络。我们平时所说的交换机，其实专业说法叫以太网交换机。而一般的光纤交换机其实也是采用以太网技术，只是传输介质由网线改成光纤。



>   以太网是一种广播类型的网络，而PPP网是点对点的，当然还有其他类型的网络。
>
>   
>
>   以太网是基于数据包交换的，而传统电话网ISDN/PSTN是基于电路交换的。
>
>   
>
>   以太网是一种局域网技术，而已经被淘汰的拨号上网（专业说法：ADSL）、十年前左右的宽度上网/猫（专业说法：PPPoE）、现在的光纤上网/光猫（专业说法：EPON，还有一个是GPON）是广域网技术。



由于以太网的好处多、多、多，上面提到的PPPoE、EPON中的E，其实就是以太网，Ethernet。



可以发现，原本是为局域网设计的技术，与其他技术结合，也可以为广域网服务。



还是由于以太网的强大，无线wifi技术也借鉴了以太网的思想，比如wifi中的mac地址，就是来自于以太网；还有wifi跟局域网一样，也是广播类型的网络。所以，无线中也有以太网的身影。



---



###### 以太网帧结构🔻



如图：



![20170313195125530](C:\Users\wonderfulfaker\Pictures\Camera Roll\20170313195125530.png)



**Preamble/SFD（Start-of-Frame Delimiter）**：每个以太网帧发送时都是以8个字节的前导码开始，Preamble是1和0交替（1 0 1 0 1 0…….）的**7个字节数据**，该部分的作用是通知接收方有数据帧到来，使其与输入的时钟保持同步，56bit 模式容许站点在帧的开始可以丢弃一些bit。



**SFD**：是一个字节10101011，最后使用11，来通知接收方下一字段就是目的主机的地址了。实际上前导码都是在物理层加进去的，并不是帧的一部分。



**DA（Destination Address）**：6个字节，目的节点的MAC地址。



**SA（Source Address）**：6个字节，源节点的MAC地址。



**Type/Length**：2字节，根据数值的不同代表2种不同的封装格式，如果字段值在0x0000－0x05DC范围内，则表示该字段为Length，该帧为802.3 raw封装。

如果字段值在0x0600－0xFFFF范围内，则表示该字段为Type字段，该帧为Ethernet II封装，0x05DD－0x05FF保留没有使用。



**PayLoad**：上层协议有效载荷，最小为46字节，最大为1500字节，对于Type封装格式，上层协议必须保证该字段的值大于46字节，对于Length封装，对于有效载荷不够46字节的报文链路层必须进行填充。



**FCR**：4字节的校验和。









---



###### 以太网技术



以太网技术指的是由Xerox公司创建并由Xerox、[Intel](https://baike.baidu.com/item/Intel/125450)和DEC公司联合开发的[基带](https://baike.baidu.com/item/基带/897959)[局域网](https://baike.baidu.com/item/局域网)规范。传统以太网络使用[CSMA/CD](https://baike.baidu.com/item/CSMA%2FCD/986847)（[载波监听多路访问](https://baike.baidu.com/item/载波监听多路访问)及[冲突检测](https://baike.baidu.com/item/冲突检测)技术）技术，并以10M/S的速率运行在多种类型的电缆上。以太网与IEEE802·3系列标准相类似。以太网不是一种具体的网络，是一种技术规范，在IEEE 802.3中定义了以太网的标准协议。 



主要分类：



**1.快速以太网**

快速以太网（Fast Ethernet）也就是我们常说的百兆以太网，它在保持帧格式、MAC（介质存取控制）机制和[MTU](https://baike.baidu.com/item/MTU/508920)（最大传送单元）质量的前提下，其速率比10Base－T的以太网增加了10倍。二者之间的相似性使得10Base－T 以太网现有的应用程序和网络管理工具能够在[快速以太网](https://baike.baidu.com/item/快速以太网/2796711)上使用。快速以太网是基于扩充的[IEEE802.3标准](https://baike.baidu.com/item/IEEE802.3标准/6813217)。



**2.千兆位以太网**

千兆位以太网是一种新型[高速局域网](https://baike.baidu.com/item/高速局域网)，它可以提供1Gbps的通信[带宽](https://baike.baidu.com/item/带宽)，采用和传统10M、100M以太网同样的CSMA/CD协议、帧格式和[帧长](https://baike.baidu.com/item/帧长/7783603)，因此可以实现在原有低速以太网基础上平滑、连续性的网络升级。只用于Point to Point，[连接介质](https://baike.baidu.com/item/连接介质/10407690)以光纤为主，最大传输距离已达到80km，可用于MAN的建设。



**3.万兆以太网**

万兆以太网技术与[千兆以太网](https://baike.baidu.com/item/千兆以太网/1179810)类似，仍然保留了以太网[帧结构](https://baike.baidu.com/item/帧结构/5921395)。通过不同的[编码方式](https://baike.baidu.com/item/编码方式)或[波分复用](https://baike.baidu.com/item/波分复用/2990709)提供10Gbit/s传输速度。所以就其本质而言，[10G以太网](https://baike.baidu.com/item/10G以太网)仍是以太网的一种类型。



**4.光纤以太网**

光纤以太网产品可以借助以太网设备采用以太网[数据包](https://baike.baidu.com/item/数据包)格式实现WAN通信业务。该技术可以适用于任何[光传输](https://baike.baidu.com/item/光传输)网络——光纤直接传输、[SDH](https://baike.baidu.com/item/SDH/413593)以及DWDM网络传输。目前，[光纤以太网](https://baike.baidu.com/item/光纤以太网/1025116)可以实现10Mbps、100Mbps以及1Gbps等[标准以太网](https://baike.baidu.com/item/标准以太网/10145419)速度。



**5.端到端以太网**

端到端以太网方案以以太网作为接入技术，不但成本低，而且[带宽](https://baike.baidu.com/item/带宽)比现行的Cable Modem、[ADSL](https://baike.baidu.com/item/ADSL/96520)、[ISDN](https://baike.baidu.com/item/ISDN/587697)、Modem接入都要高，因此不但可以作为一般用户Internet连接，或者多媒体点播或广播用途，更可以作为企业用户实现VPN虚拟私有专网互联使用。



---



#### 链路层交换机



主要功能：



-   接收链路层帧并将之转发到相应出链路；
-   交换机对子网中的主机和路由器是透明的，即主机和路由器不必要了解交换机
    的存在；

-   **过滤**：决定是否应丢弃帧
-   **转发** ：决定接收的帧应当被导向哪个接口，并将帧移动到该接口



过滤和转发的功能都是依靠交换机表实现的。



**交换机表**



-   实现过滤和转发功能；
-   交换机表包含对应于某局域网上某些主机和路由器的表项；
-   表项包含MAC地址字段，通向该地址的交换机接口字段，表项放置在表中的时间字段；



**交换机行为**



设若从交换机接口x到达一个目的地为MAC A的帧

-   若无A对应的表项，交换机广播该帧；即向接口x以外的所有接口输出该帧；
-   若A对应的表项将A映射到接口x，交换机丢弃该帧；
-   若A对应的表项将A映射到接口y，交换机将该帧放入y的输出缓存以待输出；





**交换机自学习**



交换机表自动，动态，自治地建立，无需网络管理员或配置协议的干预；



**自学习过程**



>   交换机表初始为空；
>
>   设在t时刻x接口上收到了一个源MAC为a的帧，则交换机设置（添加或更新）一个以t为初始时间字段，x为接口字段，a为MAC地址字段的表项；故而，若局域网中的节点发送了帧，交换机便会自动地记录下相应信息；
>
>   若在老化期内，交换机一直没接收到某个已有表项所对应的帧，交换机将清除该表项；
>
>   交换机即插即用双全工；



---



**交换机性质**



-   **消除碰撞** 交换机缓存帧且决不会在网段上同时传输多个帧，故不可能发生碰撞；
-   **异质链路** 交换机将链路彼此隔离，故局域网可以使用不同速率乃至不同媒介的链路。易于实现新旧设备的混用；
-   **管理** 安全性更强，网络管理更方便。交换机可以智能检测某些问题并断开异常链路，同时交换机也能收集网络流量信息以便调试管理；



---



**交换机与路由器**



**交换机**



-   交换机即插即用
-   交换网络的活跃拓扑被限制为一颗生成树，因为冗余路径会导致广播帧的循环；
-   大型交换网络要求在主机和路由器中维护大ARP表
-   交换机对于广播风暴不提供保护措施



**路由器**



-   路由器需人工配置（IP等）
-   路由网络拓扑结构灵活，允许冗余路径；
-   路由器提供更健壮地流量隔离和对第二层的广播风暴的控制；





因此，对于小网络，交换机就足够了，但是在几千台主机组成的更大的网络中，路由器可以提供更加健壮的==流量隔离==方式和对于==广播风暴==的控制。







---



#### 虚拟局域网





虚拟居域网和居域网是一个概念上的分支，虚拟的局域网通常是通过一台主机来实现的，就是一台主机有一个庞大的硬盘和数据处理能力，然后下面的子机都不用配置硬盘，而是通过软件来实现读取主机上的数据，俗称==无盘系统==。居域网就是几台机子通过交换机或路由器来互相交换数据。



一、**虚拟局域网（Virtual Local Area Network，VLAN）**是一组逻辑上的设备和用户，这些设备和用户并不受物理位置的限制，可以根据功能、部门及应用等因素将它们组织起来，相互之间的通信就好像它们在同一个网段中一样，由此得名虚拟局域网。



VLAN是一种比较新的技术，工作在OSI参考模型的第2层和第3层，一个VLAN就是一个广播域，VLAN之间的通信是通过第3层的路由器来完成的。



与传统的局域网技术相比较，VLAN技术更加灵活，



它具有以下优点： 网络设备的移动、添加和修改的管理开销减少；可以控制广播活动；可提高网络的安全性。



二、**局域网（Local Area Network，LAN）**是指在某一区域内由多台计算机互联成的计算机组。



一般是方圆几千米以内。局域网可以实现文件管理、应用软件共享、打印机共享、工作组内的日程安排、电子邮件和传真通信服务等功能。



局域网是封闭型的，可以由办公室内的两台计算机组成，也可以由一个公司内的上千台计算机组成。





**扩展：**



网络虚拟化过程中主要诞生过 4 类过渡技术：



**虚拟局域网络（VLAN）、虚拟专用网络（VPN）、主动可编程网络（APN）、覆盖网络**。



网络虚拟化的研究现在主要集 中于 3 个领域：**云计算应用、平台化实现、软件定义网络**。



认为网络虚拟化的未来在 性能保障、可靠性、易用性和完备性等方面需要加强，为此未来的网络虚拟化需要 优化自身服务结构，并向无线网络、光网络等领域推广，此外还需要提供更加友好 的可编程接口（API）以及网络功能。







---



### 链路虚拟化（网络作为链路层）



在之前的学习中，两台主机端之间的连接一般都是默认为真实的物理链路连接的，但实际上，是一条共享线路连接起来的，而且连接主机的这种线路之间可能有无限的频道，其他的媒体等，为此我们通常将其抽象为一条==信道==。



本节中主要的是==多协议标签交换（MPLS）网络==，它与电路交换的电话网不同，客观上来说是一种分组交换的虚电路网络。



他有自己的分组格式和转发行为，<u>为IP设备提供互联服务</u>的链路层技术。因此在链路层讨论MPLS。



MPLS 是利用==标记（label）==进行数据转发的。



当分组进入网络时，要为其分配固定长度的短的标记，并将标记与分组封装在一起，在整个转发过程中，交换节点仅根据标记进行转发。



MPLS 独立于第二和第三层协议，诸如 ATM 和 IP。它提供了一种方式，将 IP 地址映射为<u>简单的具有固定长度的标签</u>，用于不同的**包转发和包交换**技术。它是现有路由和交换协议的==接口==，如 **IP、ATM、帧中继、资源预留协议（RSVP）、开放最短路径优先（OSPF）**等等。



在 MPLS 中，数据传输发生在==标签交换路径==（(Label Switching Path) ，LSP）上。



LSP 是每一个沿着从源端到终端的路径上的结点的标签序列。



优点：



>   基于固定长度标签和虚电路的技术，让路 由器根据固定长度的标签转发数据报 (而不是目的地 IP 地址)，从而**加快转发速度** (标签长 度固定、较小的标签	    空间这两个特点加快了查表速度)。
>
>   
>
>   能够**主观能动地进行流量管理**，例如：主机到目的地有多条路径可以走，但是在**IP协议路由选择**算法中只指定最小费用路径，而在MPLS中，提供了多条路径转发的功能。



==流量管理==，是使用了**流量工程**的技术，目前，MPLS以及被用于实现**虚拟专用网络**（VPN）。



---



#### **虚拟专用网络**（VPN）



具体的是：ISP使用它的MPLS主管能动地将用户于各种网络连接在一起，将资源和用户的VPN使用寻址地方式相互隔离，其它用户利用该VPN跨越了该ISP网络。



vpn 基本特征：



>   专用（private）：VPN 与底层承载网络之间保持资源独立，即 VPN 资源不被网络中非该 VPN 的用户所使用，且 VPN 能够提供足够的安全保证，确保 VPN 内部信息不受外部侵扰。
>
>   
>
>    虚拟（virtual）：逻辑上的专网 



vpn 的优势： 安全、廉价、支持移动业务、可扩展性 



vpn 的原理： 利用隧道技术，把 VPN 报文封装在隧道中，利用 VPN 骨干网建立专用数据传输通道，实现报文的透明传输。 隧道技术使用一种协议封装另外一种协议报文，而封装协议本身也可以被其他封装协议所封装或承载。







---



### 数据中心网络



#### 简介



**等级体系结构**



在传统的大型数据中心，网络通常是三层结构。Cisco 称之为：分级的互连网络模型（hierarchical inter-networking model）。这个模型包含了以下三层：



-   Access Layer（接入层）：有时也称为 Edge Layer。接入交换机通常位于机架顶部，所以它们也被称为 ToR（Top of Rack）交换机，它们物理连接服务器。
-   Aggregation Layer（汇聚层）：有时候也称为 Distribution Layer。汇聚交换机连接 Access 交换机，同时提供其他的服务，例如防火墙，SSL offload，入侵检测，网络分析等。
-   Core Layer（核心层）：核心交换机为进出数据中心的包提供高速的转发，为多个汇聚层提供连接性，核心交换机为通常为整个网络提供一个弹性的 L3 路由网络。



一个三层网络架构示意图如下所示：



![IMG_1576(20210412-131014)](C:\Users\wonderfulfaker\Pictures\Camera Roll\IMG_1576(20210412-131014).PNG)









随着云计算的发展，计算资源被池化，为了使得计算资源可以任意分配，需要一个大二层的网络架构。



即整个数据中心网络都是一个 L2 广播域，这样，服务器可以在任意地点创建，迁移，而不需要对 IP 地址或者默认网关做修改。



大二层网络架构，L2/L3 分界在核心交换机，==核心交换机==以下，也就是整个==数据中心==，是 L2 网络（当然，可以包含多个 VLAN，VLAN 之间通过核心交换机做路由进行连通）。



大二层如图所示：



![v2-c5e31e52e4bc4326ebeb3cd4ac56b8ea_1440w](C:\Users\wonderfulfaker\Pictures\Camera Roll\v2-c5e31e52e4bc4326ebeb3cd4ac56b8ea_1440w.jpg)





---



#### 数据中心发展趋势



数据中心是为了数据服务。随着技术的发展，数据的内容和形式也发生了变化。



-   **虚拟化的流行**。传统的数据中心中，服务器的利用率并不高，采用三层网络架构配合一定的超占比（oversubscription），能够有效的共享利用核心交换机和一些其他网络设备的性能。但是虚拟化的流行使得服务器的利用率变高，一个物理服务器可以虚拟出多个虚拟机，分别运行各自的任务，走自己的网络路径。因此，高的服务器利用率要求更小的超占比。Gartner 的一份报告：[Forecast: x86 Server Virtualization, Worldwide, 2012-2018, 2014 Update](https://link.zhihu.com/?target=https%3A//www.gartner.com/doc/2911617/forecast-x-server-virtualization-worldwide) 指出，在 2018 年，82% 的服务器将是虚拟服务器。虚拟化对数据中心网络架构的影响是巨大的。
-   **软件架构的解耦**。传统的软件架构，采用专用模式进行部署，软件系统通常跑在一个物理服务器，与其他的系统做物理隔离。但是，模块化，分层的软件架构设计已经成为了现在的主流。一个系统的多个组件通常分布在多个虚机 / 容器中。最典型的就是三层 WEB 应用，包含了 Client/Application/DB。一次请求，不再是由一个虚机 / 物理机完成，而是由多个服务器协同完成。这对网络的影响是，==东西向流量==变多了。
-   **新的应用的兴起**。传统数据中心是为.com 应用设计的，这些流量大多是客户端和服务器之间的通信。而==分布式计算==，大数据渐渐兴起，这些应用会在数据中心的服务器之间产生大量的流量。例如 ==Hadoop==，将数据分布在数据中心中成百上千个服务器中，进行并行计算。据说 Facebook 的一个 Hadoop 集群有着超过 100 petabytes 的数据。可见<u>对于某些应用，数据中心的东西向流量是巨大的</u>。
-   **软件定义数据中心**（SDDC，Software Defined Data Center）的提出。SDDC 提出软件定义的数据中心，这要求<u>数据中心的计算存储网络都是可以软件定义的</u>。对应于网络，就是 SDN。传统的三层网络架构在设计之初并没有考虑 SDN。

总结起来，**技术发展要求新的数据中心有更小的超占比，甚至没有超占比；更高的东西向流量带宽；支持 SDN。**





各种向流量是什么？



-   ==南北向流量==：数据中心之外的客户端到数据中心服务器之间的流量，或者数据中心服务器访问互联网的流量。
-   ==东西向流量==：数据中心内的服务器之间的流量。
-   ==跨数据中心==流量：跨数据中心的流量，例如数据中心之间的灾备，私有云和公有云之间的通讯。





**未来：**



由于成本和运维因素，数据中心一般是大企业才有能力部署。但是随着技术的发展，一些中小型企业也需要部署数据中心。不同的是，中小型企业的需求一般是（==具有成长性==），以一个小规模启动，随着自身业务的增长再逐步的扩展数据中心。数据中心的规模很大程度上取决于网络的规模，对应网络的需求就是，以一个低成本，小规模的网络架构启动，但是要能够水平扩展到较大规模。



传统三层网络架构的规模取决于核心层设备的性能和规模，取决于交换机的端口密度。最大的数据中心对应着体积最大和性能最高的网络设备，这种规模的设备并非所有的网络设备商都能提供，并且对应的资金成本和运维成本也较高。采用传统三层网络架构，企业将**面临成本和可扩展性的两难选择**。



传统的三层网络架构必然不会在短期内消失，但是由于技术和市场的发展，其短板也越来越明显。基于现有网络架构的改进显得非常有必要，新的网络架构最好是：<u>由相对较小规模的交换机构成，可以方便的水平扩展，较好的支持 HA（active-active 模式），支持全速的东西向流量，不采购高性能的核心交换机也能去除超占比，支持 SDN</u> 等等。







---





#### 负载均衡



通常的解释：



**负载均衡（Load Balance），意思是将负载（工作任务，访问请求）进行平衡、分摊到多个操作单元（服务器，组件）上进行执行。是解决高性能，单点故障（高可用），扩展性（水平伸缩）的终极解决方案。**





外部用户请求首先被定位到负载均衡器（load balancer），它的主要任务是向主机分发请求，**以主机当前的负载作为函数**来在主机之间均衡负载。



主要是基于分组的目的端口号以及目的IP地址做决策，所以也常常被称为第四层的交换机，数据中心中处理请求和返回请求<u>都需要通过负载均衡器</u>。



它还有类似于NAT（网络地址转换）的功能，可以将外部IP地址转换为内部适当主机的IP地址，这可以防止用户直接接触主机，保护了内部网络，提高了安全性。



---



**负载均衡工具**



市面上有很多开源的负载均衡的工具或软件，基本都是基于前面提到的方案实现的，大多数是工作在第七层和第四层的。Nginx/LVS/HAProxy 是目前使用最广泛的三种负载均衡软件。



**LVS** ：**LVS 主要用来做四层（运输层）负载均衡**



LVS（Linux Virtual Server），也就是 Linux 虚拟服务器，是一个由章文嵩博士发起的自由软件项目。使用 LVS 技术要达到的目标是：通过 LVS 提供的负载均衡技术和 Linux 操作系统实现一个高性能、高可用的服务器群集，它具有良好可靠性、可扩展性和可操作性。从而以低廉的成本实现最优的服务性能。



**Nginx** ：**Nginx 主要用来做七层（应用层）负载均衡**



Nginx（发音同 engine x）是一个网页服务器，它能反向代理 HTTP, HTTPS, SMTP, POP3, IMAP 的协议链接，以及一个负载均衡器和一个 HTTP 缓存。



**HAProxy** ：**HAProxy 主要用来做七层（应用层）负载均衡**



HAProxy 是一个使用 C 语言编写的自由及开放源代码软件，其提供高可用性、负载均衡，以及基于 TCP 和 HTTP 的应用程序代理。

 

---





**可以用于负载均衡的技术：**



Redis（Remote Dictionary Server )，即远程字典服务，是一个开源的使用 ANSI [C 语言](https://baike.baidu.com/item/C语言)编写、支持网络、可基于内存亦可持久化的日志型、Key-Value [数据库](https://baike.baidu.com/item/数据库/103728)，并提供多种语言的 API。



Redis 是一个高性能的 key-value 数据库。









---





#### 负载均衡算法



负载均衡服务器在决定将请求转发到具体哪台真实服务器的时候，是通过负载均衡算法来实现的。负载均衡算法，是一个负载均衡服务器的核心。



就像电影院门口的引导员一样，他根据什么把排队人员分配到具体的入口呢？是哪个入口人少吗？还是哪个入口速度最快？还是哪个入口最近呢？



负载均衡算法可以分为两类：==静态负载均衡算法==和==动态负载均衡算法==。



1）静态负载均衡算法包括：轮询，比率，优先权



-   **轮询（Round Robin）：**顺序循环将请求一次顺序循环地连接每个服务器。当其中某个服务器发生第二到第 7 层的故障，BIG-IP 就把其从顺序循环队列中拿出，不参加下一次的轮询，直到其恢复正常。
-   **比率（Ratio）：**给每个服务器分配一个加权值为比例，根椐这个比例，把用户的请求分配到每个服务器。当其中某个服务器发生第二到第 7 层的故障，BIG-IP 就把其从服务器队列中拿出，不参加下一次的用户请求的分配，直到其恢复正常。
-   **优先权（Priority）：**给所有服务器分组，给每个组定义优先权，BIG-IP 用户的请求，分配给优先级最高的服务器组（在同一组内，采用轮询或比率算法，分配用户的请求）；当最高优先级中所有服务器出现故障，BIG-IP 才将请求送给次优先级的服务器组。这种方式，实际为用户提供一种热备份的方式。



2) 动态负载均衡算法包括：最少连接数，最快响应速度，观察方法，预测法，动态性能分配，动态服务器补充，服务质量，服务类型，规则模式。



-   **最少的连接方式（Least Connection）：**传递新的连接给那些进行最少连接处理的服务器。当其中某个服务器发生第二到第 7 层的故障，BIG-IP 就把其从服务器队列中拿出，不参加下一次的用户请求的分配，直到其恢复正常。
-   **最快模式（Fastest）：**传递连接给那些响应最快的服务器。当其中某个服务器发生第二到第 7 层的故障，BIG-IP 就把其从服务器队列中拿出，不参加下一次的用户请求的分配，直到其恢复正常。
-   **观察模式（Observed）：**连接数目和响应时间以这两项的最佳平衡为依据为新的请求选择服务器。当其中某个服务器发生第二到第 7 层的故障，BIG-IP 就把其从服务器队列中拿出，不参加下一次的用户请求的分配，直到其恢复正常。
-   **预测模式（Predictive）：**BIG-IP 利用收集到的服务器当前的性能指标，进行预测分析，选择一台服务器在下一个时间片内，其性能将达到最佳的服务器相应用户的请求。(被 BIG-IP 进行检测)
-   **动态性能分配 (Dynamic Ratio-APM)：**BIG-IP 收集到的应用程序和应用服务器的各项性能参数，动态调整流量分配。
-   **动态服务器补充 (Dynamic Server Act.)：**当主服务器群中因故障导致数量减少时，动态地将备份服务器补充至主服务器群。
-   **服务质量 (QoS）：**按不同的优先级对数据流进行分配。
-   **服务类型 (ToS)：**按不同的服务类型（在 Type of Field 中标识）负载均衡对数据流进行分配。
-   **规则模式：**针对不同的数据流设置导向规则，用户可自行。



以上，就是目前实现负载均衡的主流算法。不同的负载均衡服务器会选择不同的算法。









---



### WEB页面请求过程



如图回忆以下请求需要用到说明协议以及协议之间的知识点：



![IMG_1579(20210412-134827)](C:\Users\wonderfulfaker\Pictures\Camera Roll\IMG_1579(20210412-134827).PNG)





**主要是从IP地址分配，HTTP传输由协议栈上往下一步步地配置地址路径，找寻目的地地址，再有下往上返回结果的过程。**





---





#### DHCP,UDP,IP和以太网



DHCP 配置主机信息



>   假设主机最开始没有 IP 地址以及其它信息，那么就需要先使用 DHCP 来获取。
>
>   
>
>   主机生成一个 DHCP 请求报文，并将这个报文放入具有目的端口 67 和源端口 68 的 UDP 报文段中。
>
>   
>
>   该报文段则被放入在一个具有**广播 IP 目的地址 (255.255.255.255)** 和源 IP 地址（0.0.0.0）的 IP 数据报中。
>
>   
>
>   该数据报则被放置在 MAC 帧中，该**帧具有目的地址 FF:FF:FF:FF:FF:FF**，将广播到与交换机连接的所有设备。
>
>   
>
>   连接在交换机的 **DHCP 服务器**收到广播帧之后，不断地向上分解得到 IP 数据报、UDP 报文段、DHCP 请求报文，之后生成 DHCP ACK 报文，该报文包含以下信息：**IP 地址、DNS 服务器的 IP 地址、默认网关路由器的 IP 地址和子网掩码**。该报文被放入 UDP 报文段中，UDP 报文段有被放入 IP 数据报中，最后放入 MAC 帧中。
>
>   
>
>   该帧的**目的地址**是请求主机的 MAC 地址，因为交换机具有自学习能力，之前主机发送了广播帧之后就记录了 MAC 地址到其转发接口的交换表项，因此现在交换机就可以直接知道应该向哪个接口发送该帧。（**因此传回的时候是使用单播点到点传输，而非广播**）
>
>   
>
>   主机收到该帧后，不断分解得到 DHCP 报文。之后就配置它的 IP 地址、子网掩码和 DNS 服务器的 IP 地址，并在其 IP 转发表中安装默认网关。













---



#### DNS和ARP



 ARP 解析 MAC 地址



>   主机通过浏览器生成一个 TCP 套接字，套接字向 HTTP 服务器发送 HTTP 请求。为了生成该套接字，**主机需要知道网站的域名对应的 IP 地址**。
>
>   
>
>   主机生成一个 DNS 查询报文，该报文具有 53 号端口，因为 DNS 服务器的端口号是 53。
>
>   
>
>   该 DNS 查询报文被放入目的地址为 DNS 服务器 IP 地址的 IP 数据报中。
>
>   
>
>   该 IP 数据报被放入一个以太网帧中，该帧将发送到**网关路由器**。
>
>   
>
>   DHCP 过程只知道网关路由器的 IP 地址，为了获取网关路由器的 MAC 地址，需要使用 ==ARP 协议==。
>
>   
>
>   主机**生成一个包含目的地址为网关路由器 IP 地址的 ARP 查询报文**，将该 ARP 查询报文放入一个具有广播目的地址（FF:FF:FF:FF:FF:FF）的以太网帧中，并向交换机发送该以太网帧，交换机将该帧转发给所有的连接设备，包括网关路由器。
>
>   
>
>   ==网关路由器==接收到该帧后，不断向上分解得到 ARP 报文，发现其中的 IP 地址与其接口的 IP 地址匹配，因此就发送一个 ARP 回答报文，包含了它的 **MAC 地址，发回给主机**。







---



#### 域内路由选择到DNS服务器



 **DNS 解析域名**



>   知道了网关路由器的 MAC 地址之后，就可以继续 DNS 的解析过程了。
>
>   
>
>   网关路由器接收到包含 DNS 查询报文的以太网帧后，抽取出 IP 数据报，并根据转发表决定该 IP 数据报应该转发的路由器。
>
>   
>
>   因为路由器具有**内部网关协议（RIP、OSPF）和外部网关协议（BGP）**这两种路由选择协议，因此路由表中已经配置了网关路由器到达 DNS 服务器的路由表项。
>
>   
>
>   到达 DNS 服务器之后，DNS 服务器抽取出 DNS 查询报文，并在 DNS 数据库中查找待解析的域名。
>
>   
>
>   找到 DNS 记录之后，发送 DNS 回答报文，将该回答报文放入 UDP 报文段中，然后放入 IP 数据报中，通过路由器反向转发回网关路由器，并经过以太网交换机到达主机。











---



#### WEB客户—服务器交互



**HTTP 请求页面**



>   有了 HTTP 服务器的 IP 地址之后，主机就能够生成 TCP 套接字，该套接字将用于向 Web 服务器发送 HTTP GET 报文。
>
>   
>
>   在生成 TCP 套接字之前，必须先与 **HTTP 服务器进行三次握手来建立连接**。生成一个具有目的端口 80 的 TCP SYN 报文段，并向 HTTP 服务器发送该报文段。
>
>   
>
>   HTTP 服务器收到该报文段之后，生成 TCP SYN ACK 报文段，发回给主机。
>
>   
>
>   连接建立之后，浏览器生成 **HTTP GET 报文**，并交付给 HTTP 服务器。
>
>   
>
>   HTTP 服务器从 TCP 套接字读取 HTTP GET 报文，生成一个 HTTP 响应报文，将 Web 页面内容放入报文主体中，发回给主机。
>
>   
>
>   浏览器收到 HTTP 响应报文后，抽取出 Web 页面内容，之后进行渲染，显示 Web 页面。











---



### 总结



为了将分组从一个节点移动到路径的下一个节点，网络层必须依靠链路层的服务。



特别是在每个节点，网络层将数据报传给链路层，链路层沿着路径将数据报传递给下一个节点。



在下一个节点，链路层将数据报上传给网络层。我们将链路层分组称为==帧==。



链路层的任务是将整个帧从一个网络元素移动到邻近的网络元素。



**主要知识点**：



链路层的主体部分是在网络适配器，即网络接口卡，即常说的 网卡



链路层提供了差错校验和重发。



校验方法主要有：



>   奇偶校验
>
>   校验和
>
>   循环冗余检测
>

 



 

时延的由来：多路访问链路协议，假如有多个节点需要传递链路帧，如果一起再同一个信道上进行传输，会产生碰撞。



为此需要进行信道的划分：



>   频分复用
>
>   时分复用
>
>   随机接入协议等

 

MAC 地址由 2 的 48 次方，6 个字节构成，MAC 地址是唯一的，通过 IEEE 组织分配 MAC 地址块

 

MAC 广播，对于使用 6 个字节的局域网（如以太网）广播地址为 FF-FF-FF-FF

 

以太网是目前较通用的局域网协议的一种，比较偏向于底层（链路，物理层的通信），而 INTERNET 网是以 TCP/IP 协议为基础的全球性通信。

 

每个 AS 自治系统都可以采用不同的路由转发协议，如 ARP（address resolution protpcol）地址解析协议，就是将 IP 转换为 MAC 地址。



ARP 协议是针对同一个子网的。













---







## 5.多媒体网络